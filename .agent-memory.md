# Critical Facts - DO NOT REDISCOVER

## Core Assumptions

**CRITICAL**: Assume your code is WRONG until proven working through full verification workflow.
**FACT**: Logs flow continuously from demo apps - if you don't see data, ingestion is broken.

## Architecture

**CRITICAL**: There are TWO separate pods:

- **ollyscale-frontend**: REST API server (port 8000) - serves /api/* endpoints
- **ollyscale-otlp-receiver**: OTLP ingestion (port 8000) - receives telemetry and writes to DB

**Deployment labels**:

- Frontend API: `app.kubernetes.io/component=frontend`
- OTLP Receiver: `app.kubernetes.io/component=receiver`

## Verification Workflow (MANDATORY ORDER)

After ANY code change or deployment:

1. **Verify Receiver** - Check OTLP ingestion is working in RECEIVER pod

   ```bash
   kubectl -n ollyscale logs deployment/ollyscale-otlp-receiver --tail=50 | grep -i "stored.*log"
   ```

2. **Verify Database** - Confirm data written with service_id populated

   ```bash
   kubectl -n ollyscale exec ollyscale-db-1 -- psql -U postgres -d ollyscale -c "SELECT time_unix_nano, service_id, severity_text FROM logs_fact ORDER BY time_unix_nano DESC LIMIT 5;"
   ```

3. **Verify API** - Test REST endpoint returns service_name

   ```bash
   curl -sk -X POST https://ollyscale.ollyscale.test:49443/api/logs/search \
     -H "Content-Type: application/json" \
     -d '{"time_range": {"start_time": 0, "end_time": 9999999999999999999}, "pagination": {"limit": 1}}' \
     | jq '.logs[0] | {service_name, severity_text, body}'
   ```

4. **Verify UI** - Only after API works, check browser at <https://ollyscale.ollyscale.test:49443>

**If ANY step fails**: Fix code, `make deploy`, start over at step 1.

## Database Connection (PostgreSQL)

**Database name**: `ollyscale` (NOT "app")
**User for queries**: `postgres` (use this in exec commands)
**Connection pattern**: `kubectl -n ollyscale exec ollyscale-db-1 -- psql -U postgres -d ollyscale -c "QUERY"`

Example:

```bash
kubectl -n ollyscale exec ollyscale-db-1 -- psql -U postgres -d ollyscale -c "SELECT COUNT(*) FROM logs_fact;"
```

## Deployment Process

**ONLY deployment method**: `make deploy`

From repo root:

```bash
make deploy
```

This handles:

- Building images
- Pushing to local registry
- Updating Helm chart
- Applying to ArgoCD

**DO NOT**:

- Manually build images
- Run individual scripts
- Use kubectl apply
- Use helm install/upgrade directly

## System Behavior

**Logs flow continuously**: The system is constantly generating telemetry (traces, logs, metrics)
**Assume you are wrong**: Do NOT assume code works until you can PROVE it works by checking the database

## Bugs Fixed (2026-01-25)

**Issue 1**: service_id NULL in logs_fact, spans_fact, metrics_fact
**Root cause**: Helper methods (_upsert_service, _upsert_operation, _upsert_resource) were calling session.commit() BEFORE parent method added fact records
**Solution**: Removed session.commit() from all helper methods - only commit once at end of transaction

**Issue 2**: NameError in store_metrics()
**Root cause**: Variable named resource_attrs_list but code referenced resource_attrs
**Solution**: Fixed variable reference to resource_attrs_list

**Status**: Code deployed, need to VERIFY service_id is populated in database
