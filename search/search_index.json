{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"Desktop-First Observability Platform for Local Development"},{"location":"#introducing-ollyscale","title":"Introducing ollyScale","text":"<p>ollyScale is an OpenTelemetry-native observability platform evolved from the excellent TinyOlly project.</p> <p>Repository: https://github.com/ryanfaircloth/ollyscale</p> <pre><code>git clone https://github.com/ryanfaircloth/ollyscale\n</code></pre>"},{"location":"#why-ollyscale","title":"Why ollyScale?","text":"<p>Why send telemetry to a cloud observability platform while coding? Why not have one on your desktop?</p> <p>ollyScale is a lightweight OpenTelemetry-native observability platform built to visualize and correlate logs, metrics, and traces. No 3rd party observability tools - just Python (FastAPI), Redis, OpenAPI, and JavaScript.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Development-focused - Perfect your app's telemetry locally before production</li> <li>Full OpenTelemetry support - Native OTLP ingestion (gRPC &amp; HTTP)</li> <li>Pre-built Docker images - Deploy in ~30 seconds from Docker Hub</li> <li>Multi-architecture - Supports linux/amd64 and linux/arm64 (Apple Silicon)</li> <li>Trace correlation - Link logs, metrics, and traces automatically</li> <li>Metrics Explorer - Analyze cardinality, labels, and raw series data</li> <li>Service catalog - RED metrics (Rate, Errors, Duration) for all services</li> <li>Interactive service map - Visualize dependencies and call graphs</li> <li>OpenTelemetry Collector management - Remote configuration management via OpAMP protocol</li> <li>REST API - Programmatic access with OpenAPI documentation</li> <li>Zero vendor lock-in - Works with any OTel Collector distribution</li> </ul> <p>Local Development Only</p> <p>ollyScale is not designed to compete with production observability platforms! It's for local development only and is not focused on infrastructure monitoring at this time.</p>"},{"location":"#platform-support","title":"Platform Support","text":"<p>Tested on:</p> <ul> <li>Docker Desktop (macOS Apple Silicon)</li> <li>Minikube Kubernetes (macOS Apple Silicon)</li> <li>May work on other platforms</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Ready to try ollyScale? Check out the Quick Start Guide to get running in under 5 minutes!</p>"},{"location":"#screenshots","title":"Screenshots","text":"Trace Waterfall with Correlated Logs Real-time Logs with Filtering Metrics with Chart Visualization Service Catalog with RED Metrics Interactive Service Dependency Map OTel Collector Configuration (OpAMP) <p>Built for the OpenTelemetry community</p> <p> GitHub \u2022     Issues </p>"},{"location":"CARDINALITY-PROTECTION/","title":"Cardinality Protection","text":"<p>Span waterfall showing distributed trace complexity</p> <p>ollyScale includes built-in protection against metric cardinality explosion with a configurable limit on unique metric names.</p>"},{"location":"CARDINALITY-PROTECTION/#configuration","title":"Configuration","text":""},{"location":"CARDINALITY-PROTECTION/#environment-variables","title":"Environment Variables","text":"Variable Default Description <code>MAX_METRIC_CARDINALITY</code> 1000 Maximum unique metric names <code>REDIS_TTL</code> 1800 Metric retention (seconds)"},{"location":"CARDINALITY-PROTECTION/#kubernetes-deployment","title":"Kubernetes Deployment","text":"<p>Update Helm values in <code>charts/ollyscale/values.yaml</code>:</p> <pre><code>otlpReceiver:\n  env:\n    MAX_METRIC_CARDINALITY: \"2000\" # Increase limit\n    REDIS_TTL: \"3600\" # 1 hour retention\n</code></pre> <p>Then upgrade the deployment:</p> <pre><code>cd charts\nhelm upgrade ollyscale ./ollyscale -n ollyscale\n</code></pre>"},{"location":"CARDINALITY-PROTECTION/#docker-deployment","title":"Docker Deployment","text":"<p>Update <code>docker-compose-ollyscale-core.yml</code> in the <code>docker/</code> directory:</p> <pre><code>environment:\n  MAX_METRIC_CARDINALITY: 2000\n  REDIS_TTL: 3600\n</code></pre>"},{"location":"CARDINALITY-PROTECTION/#monitoring","title":"Monitoring","text":"<p>The UI displays cardinality warnings when approaching the limit:</p> <ul> <li>Yellow Warning: 70-90% of limit reached</li> <li>Red Alert: 90%+ of limit reached</li> </ul> <p>Check current cardinality via the API:</p> <pre><code>curl http://localhost:5005/api/stats\n</code></pre> <p>Response:</p> <pre><code>{\n  \"traces\": 145,\n  \"logs\": 892,\n  \"metrics\": 850,\n  \"metrics_max\": 1000,\n  \"metrics_dropped\": 23\n}\n</code></pre>"},{"location":"ai-agent-deployment/","title":"ollyScale AI Agent Demo - Deployment Guide","text":""},{"location":"ai-agent-deployment/#overview","title":"Overview","text":"<p>The ollyScale AI Agent demo has been refactored to use Helm charts with OTel operator auto-instrumentation. This provides a cleaner, more maintainable deployment approach compared to the previous manual Kubernetes manifests.</p>"},{"location":"ai-agent-deployment/#what-changed","title":"What Changed","text":""},{"location":"ai-agent-deployment/#before-old-approach","title":"Before (Old Approach)","text":"<ul> <li>Manual Kubernetes YAML files in <code>scripts/k8s/ai-agent-demo/</code></li> <li>Manual OTLP configuration via environment variables</li> <li>Separate deployment and cleanup scripts</li> <li>No GitOps integration</li> </ul>"},{"location":"ai-agent-deployment/#after-new-approach","title":"After (New Approach)","text":"<ul> <li>Helm chart in <code>charts/ollyscale-ai-agent/</code></li> <li>OTel operator auto-instrumentation (zero-code)</li> <li>ArgoCD GitOps deployment</li> <li>Integrated with local registry and build scripts</li> </ul>"},{"location":"ai-agent-deployment/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502           ollyscale-ai-agent                 \u2502\n\u2502                                             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  AI Agent    \u2502\u2500\u2500\u2500\u2500\u2500\u25b6\u2502    Ollama      \u2502  \u2502\n\u2502  \u2502              \u2502      \u2502   (tinyllama)  \u2502  \u2502\n\u2502  \u2502 OTel Auto-   \u2502      \u2502                \u2502  \u2502\n\u2502  \u2502 Instrumented \u2502      \u2502  Persistent    \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502  Storage       \u2502  \u2502\n\u2502         \u2502              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502         \u2502                                   \u2502\n\u2502         \u2502 OTLP (auto-configured)            \u2502\n\u2502         \u25bc                                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                      \u2502\n\u2502  \u2502 Agent Collector  \u2502                      \u2502\n\u2502  \u2502   (in ollyscale)  \u2502                      \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ai-agent-deployment/#deployment","title":"Deployment","text":""},{"location":"ai-agent-deployment/#automated-recommended","title":"Automated (Recommended)","text":"<p>The AI agent demo is automatically deployed via ArgoCD when you run:</p> <pre><code>make up\n</code></pre> <p>This will:</p> <ol> <li>Create the KIND cluster</li> <li>Install ArgoCD</li> <li>Deploy infrastructure (including OTel operator)</li> <li>Deploy ollyScale platform</li> <li>Deploy AI agent demo</li> </ol>"},{"location":"ai-agent-deployment/#manual-build-and-deploy","title":"Manual Build and Deploy","text":"<p>If you make changes to the AI agent code:</p> <pre><code># Build all images including AI agent\ncd charts\n./build-and-push-local.sh v2.2.0-my-changes\n\n# ArgoCD will automatically sync the new version\n# Or force sync:\ncd ../.kind\nterraform apply -auto-approve\n</code></pre>"},{"location":"ai-agent-deployment/#chart-only-update","title":"Chart-only Update","text":"<p>If you only changed the Helm chart (no code changes):</p> <pre><code>cd charts\nhelm package ollyscale-ai-agent\nhelm push ollyscale-ai-agent-0.1.0.tgz oci://registry.ollyscale.test:49443/ollyscale/charts --insecure-skip-tls-verify\n\n# Update ArgoCD\ncd ../.kind\nterraform apply -auto-approve\n</code></pre>"},{"location":"ai-agent-deployment/#configuration","title":"Configuration","text":""},{"location":"ai-agent-deployment/#default-values","title":"Default Values","text":"<p>See <code>charts/ollyscale-ai-agent/values.yaml</code> for all configuration options.</p> <p>Key defaults:</p> <ul> <li>Namespace: <code>ollyscale-ai-agent</code></li> <li>Ollama model: <code>tinyllama</code></li> <li>Ollama storage: 10Gi persistent volume</li> <li>Ollama resources: 2 CPU / 4Gi RAM (limit)</li> <li>Agent resources: 500m CPU / 512Mi RAM (limit)</li> <li>HTTPRoute: Disabled (no external access by default)</li> </ul>"},{"location":"ai-agent-deployment/#customization","title":"Customization","text":"<p>To override values, edit <code>.kind/modules/ollyscale/argocd-applications/observability/ollyscale-ai-agent.yaml</code>:</p> <pre><code>spec:\n  source:\n    helm:\n      valuesObject:\n        ollama:\n          model: llama2 # Use different model\n          resources:\n            limits:\n              cpu: \"4000m\"\n              memory: \"8Gi\"\n\n        agent:\n          httpRoute:\n            enabled: true # Enable external access\n</code></pre>"},{"location":"ai-agent-deployment/#verification","title":"Verification","text":""},{"location":"ai-agent-deployment/#check-deployment-status","title":"Check Deployment Status","text":"<pre><code># Check ArgoCD application\nkubectl get application -n argocd ollyscale-ai-agent\n\n# Check pods\nkubectl get pods -n ollyscale-ai-agent\n\n# Check services\nkubectl get svc -n ollyscale-ai-agent\n</code></pre>"},{"location":"ai-agent-deployment/#view-logs","title":"View Logs","text":"<pre><code># Agent logs (should show successful LLM calls)\nkubectl logs -n ollyscale-ai-agent deployment/ai-agent -f\n\n# Ollama logs (should show model downloads)\nkubectl logs -n ollyscale-ai-agent deployment/ollama -f\n</code></pre>"},{"location":"ai-agent-deployment/#verify-auto-instrumentation","title":"Verify Auto-Instrumentation","text":"<pre><code># Check if init container was injected\nkubectl get pod -n ollyscale-ai-agent -l app=ai-agent \\\n  -o jsonpath='{.items[0].spec.initContainers[*].name}'\n# Should output: opentelemetry-auto-instrumentation-python\n\n# Check OTLP endpoint configuration\nkubectl get pod -n ollyscale-ai-agent -l app=ai-agent \\\n  -o jsonpath='{.items[0].spec.containers[0].env[?(@.name==\"OTEL_EXPORTER_OTLP_ENDPOINT\")].value}'\n# Should output: http://agent-collector.ollyscale.svc.cluster.local:4318\n</code></pre>"},{"location":"ai-agent-deployment/#check-traces-in-ollyscale-ui","title":"Check Traces in ollyScale UI","text":"<ol> <li>Port-forward to ollyScale UI:</li> </ol> <pre><code>kubectl port-forward -n ollyscale svc/ollyscale-ui 5002:5002\n</code></pre> <ol> <li> <p>Open browser: http://localhost:5002</p> </li> <li> <p>Filter for service: <code>ai-agent</code></p> </li> <li> <p>Look for GenAI spans with attributes:</p> </li> <li><code>gen_ai.system</code>: \"ollama\"</li> <li><code>gen_ai.request.model</code>: \"tinyllama\"</li> <li><code>gen_ai.prompt</code>: User prompt text</li> <li><code>gen_ai.completion</code>: LLM response</li> </ol>"},{"location":"ai-agent-deployment/#troubleshooting","title":"Troubleshooting","text":""},{"location":"ai-agent-deployment/#ollama-not-ready","title":"Ollama Not Ready","text":"<p>If Ollama pod stays in \"NotReady\":</p> <pre><code># Check if model is downloading\nkubectl logs -n ollyscale-ai-agent deployment/ollama\n\n# Verify model is pulled\nkubectl exec -n ollyscale-ai-agent deployment/ollama -- ollama list\n</code></pre> <p>Model download can take several minutes depending on network speed.</p>"},{"location":"ai-agent-deployment/#agent-cant-connect-to-ollama","title":"Agent Can't Connect to Ollama","text":"<p>If agent logs show connection errors:</p> <pre><code># Verify Ollama service\nkubectl get svc -n ollyscale-ai-agent ollama\n\n# Check Ollama pod is ready\nkubectl get pods -n ollyscale-ai-agent -l app=ollama\n</code></pre>"},{"location":"ai-agent-deployment/#no-traces-appearing","title":"No Traces Appearing","text":"<p>If traces aren't showing in ollyScale:</p> <pre><code># Verify instrumentation annotation\nkubectl get deployment -n ollyscale-ai-agent ai-agent -o yaml | grep instrumentation\n\n# Check OTel operator logs\nkubectl logs -n opentelemetry-operator-system deployment/opentelemetry-operator\n\n# Verify Python instrumentation resource exists\nkubectl get instrumentation -n ollyscale python-instrumentation\n</code></pre>"},{"location":"ai-agent-deployment/#cleanup","title":"Cleanup","text":""},{"location":"ai-agent-deployment/#remove-ai-agent-demo","title":"Remove AI Agent Demo","text":"<pre><code># Delete via ArgoCD\nkubectl delete application -n argocd ollyscale-ai-agent\n\n# Or delete namespace directly\nkubectl delete namespace ollyscale-ai-agent\n</code></pre>"},{"location":"ai-agent-deployment/#full-cluster-teardown","title":"Full Cluster Teardown","text":"<pre><code>make down\n</code></pre>"},{"location":"ai-agent-deployment/#migration-notes","title":"Migration Notes","text":"<p>If you were using the old K8s deployment method:</p> <ol> <li>The old files in <code>scripts/k8s/ai-agent-demo/</code> have been removed</li> <li>Old deployment scripts no longer work</li> <li>Use <code>make up</code> to deploy the new Helm-based version</li> <li>Configuration is now in the Helm chart values</li> <li>Deployment is managed by ArgoCD</li> </ol>"},{"location":"ai-agent-deployment/#files-reference","title":"Files Reference","text":"<ul> <li>Helm Chart: <code>charts/ollyscale-ai-agent/</code></li> <li>ArgoCD App: <code>.kind/modules/ollyscale/argocd-applications/observability/ollyscale-ai-agent.yaml</code></li> <li>Terraform Config: <code>.kind/modules/ollyscale/variables.tf</code> (ai_agent_image, ai_agent_tag)</li> <li>Build Script: <code>charts/build-and-push-local.sh</code></li> <li>Application Code: <code>apps/ai-agent-demo/</code></li> </ul>"},{"location":"ai-agent/","title":"AI Agent Demo","text":"<p>This demo showcases GenAI observability with OpenTelemetry - automatic instrumentation of LLM calls using the <code>opentelemetry-instrumentation-ollama</code> package.</p>"},{"location":"ai-agent/#what-is-genai-observability","title":"What is GenAI Observability?","text":"<p>GenAI observability captures telemetry from LLM interactions including:</p> <ul> <li>Prompts and responses - Full text of user prompts and model outputs</li> <li>Token usage - Input and output token counts</li> <li>Latency - Response time for each LLM call</li> <li>Model information - Which model was used</li> </ul>"},{"location":"ai-agent/#quick-start","title":"Quick Start","text":""},{"location":"ai-agent/#docker","title":"Docker","text":"<pre><code># Start ollyScale core first\ncd docker\n./01-start-core.sh\n\n# Deploy AI agent demo (pulls pre-built images from Docker Hub)\ncd ../docker-ai-agent-demo\n./01-deploy-ai-demo.sh\n</code></pre> <p>This starts:</p> <ul> <li>Ollama with TinyLlama model for local LLM inference</li> <li>AI Agent with automatic GenAI span instrumentation</li> </ul> <p>Access the UI at <code>http://localhost:5005</code> and navigate to the AI Agents tab.</p> <p>For local development: Use <code>./01-deploy-ai-demo-local.sh</code> to build locally</p> <p>Stop: <code>./02-stop-ai-demo.sh</code></p> <p>Cleanup (remove volumes): <code>./03-cleanup-ai-demo.sh</code></p>"},{"location":"ai-agent/#how-it-works","title":"How It Works","text":"<p>The demo uses zero-code auto-instrumentation - no OpenTelemetry imports in the application code:</p> <pre><code># agent.py - NO OpenTelemetry imports needed!\nfrom ollama import Client\n\nclient = Client(host=\"http://ollama:11434\")\n\n# This call is AUTO-INSTRUMENTED\nresponse = client.chat(\n    model=\"tinyllama\",\n    messages=[{\"role\": \"user\", \"content\": \"What is OpenTelemetry?\"}]\n)\n</code></pre> <p>The magic happens in the Dockerfile:</p> <pre><code># Install auto-instrumentation packages\nRUN pip install opentelemetry-distro opentelemetry-instrumentation-ollama\n\n# Run with auto-instrumentation wrapper\nCMD [\"opentelemetry-instrument\", \"python\", \"-u\", \"agent.py\"]\n</code></pre>"},{"location":"ai-agent/#what-youll-see","title":"What You'll See","text":"<p>In the AI Agents tab:</p> Field Description Prompt The user's input to the LLM Response The model's output Tokens In Number of input tokens Tokens Out Number of output tokens Latency Response time in milliseconds Model Model name (e.g., <code>tinyllama</code>) <p>Click any row to expand the full span details in JSON format.</p>"},{"location":"ai-agent/#supported-llms","title":"Supported LLMs","text":"<p>The OpenTelemetry GenAI semantic conventions work with any instrumented LLM provider:</p> <ul> <li>Ollama - Local LLM inference (this demo)</li> <li>OpenAI - GPT models via <code>opentelemetry-instrumentation-openai</code></li> <li>Anthropic - Claude models</li> <li>Other providers - Any with OpenTelemetry instrumentation</li> </ul>"},{"location":"ai-agent/#configuration","title":"Configuration","text":"<p>The demo is configured via environment variables in <code>docker-compose.yml</code>:</p> <pre><code>ai-agent:\n  environment:\n    - OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317\n    - OTEL_SERVICE_NAME=ai-agent-demo\n    - OLLAMA_HOST=http://ollama:11434\n</code></pre>"},{"location":"ai-agent/#troubleshooting","title":"Troubleshooting","text":"<p>No AI traces appearing?</p> <ul> <li>Ensure ollyScale core is running</li> <li>Check agent logs: <code>docker logs ai-agent-demo</code></li> <li>Verify Ollama is ready: <code>docker logs ollama</code></li> </ul> <p>Model download taking long?</p> <ul> <li>TinyLlama is ~600MB, first download may take a few minutes</li> <li>Check Ollama logs for download progress</li> </ul> <p>Agent errors?</p> <ul> <li>Ollama needs time to load the model after container starts</li> <li>The agent waits 10 seconds before first call</li> </ul>"},{"location":"api/","title":"REST API &amp; OpenAPI","text":"<p>OpenAPI documentation with interactive Swagger UI</p> <p>ollyScale provides a comprehensive REST API for programmatic access to all telemetry data in OpenTelemetry-native format.</p>"},{"location":"api/#interactive-api-documentation","title":"Interactive API Documentation","text":"<p>Access the auto-generated OpenAPI documentation:</p> <ul> <li>Swagger UI: <code>http://localhost:5005/docs</code> - Interactive API explorer</li> <li>ReDoc: <code>http://localhost:5005/redoc</code> - Alternative documentation</li> <li>OpenAPI Spec: <code>http://localhost:5005/openapi.json</code> - Machine-readable schema</li> </ul> <p>All APIs return OpenTelemetry-native JSON with:</p> <ul> <li>Resources: <code>service.name</code>, <code>host.name</code>, etc.</li> <li>Attributes: Metric labels and span attributes</li> <li>Full Context: Trace/span IDs, timestamps, status codes</li> </ul>"},{"location":"api/#api-endpoints-overview","title":"API Endpoints Overview","text":"<p>The REST API provides endpoints for:</p> Endpoint Method Description <code>/api/traces</code> GET List recent traces with filtering <code>/api/traces/{trace_id}</code> GET Get detailed trace with all spans <code>/api/spans</code> GET List recent spans with filtering <code>/api/logs</code> GET Retrieve logs with trace correlation <code>/api/metrics</code> GET Query time-series metrics <code>/api/service-map</code> GET Get service dependency graph <code>/api/service-catalog</code> GET List services with RED metrics <code>/api/stats</code> GET System stats and cardinality info <code>/admin/stats</code> GET Detailed admin statistics <code>/health</code> GET Health check endpoint <p>All endpoints return data in standard OpenTelemetry format, ensuring compatibility with OpenTelemetry tooling and standards.</p>"},{"location":"api/#common-api-workflows","title":"Common API Workflows","text":""},{"location":"api/#1-get-all-recent-traces","title":"1. Get All Recent Traces","text":"<p>Retrieve the last 50 traces:</p> cURL <p><code>bash     curl http://localhost:5005/api/traces?limit=50</code></p> Python <pre><code>import requests\n\n    response = requests.get('http://localhost:5005/api/traces', params={'limit': 50})\n    traces = response.json()\n\n    for trace in traces:\n        print(f\"Trace {trace['trace_id']}: {trace['service_name']} - {trace['name']}\")\n    ```\n\n=== \"JavaScript\"\n``javascript\n    fetch('http://localhost:5005/api/traces?limit=50')\n      .then(response =&gt; response.json())\n      .then(traces =&gt; {\n        traces.forEach(trace =&gt; {\n          console.log(`Trace ${trace.trace_id}: ${trace.service_name} - ${trace.name}`);\n        });\n      });\n    ``\n\n**Response Format:**\n\n```json\n[\n  {\n    \"trace_id\": \"a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6\",\n    \"service_name\": \"demo-frontend\",\n    \"name\": \"GET /products\",\n    \"start_time\": 1701234567890000000,\n    \"duration_ms\": 125.4,\n    \"status_code\": 200,\n    \"method\": \"GET\",\n    \"route\": \"/products\",\n    \"span_count\": 5\n  }\n]\n</code></pre>"},{"location":"api/#2-get-detailed-trace-with-waterfall","title":"2. Get Detailed Trace with Waterfall","text":"<p>Retrieve a complete trace with all spans for waterfall visualization:</p> cURL <p><code>bash     curl http://localhost:5005/api/traces/a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6</code></p> Python <pre><code>import requests\n\n    trace_id = \"a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6\"\n    response = requests.get(f'http://localhost:5005/api/traces/{trace_id}')\n    trace = response.json()\n\n    print(f\"Trace: {trace['name']}\")\n    print(f\"Total spans: {len(trace['spans'])}\")\n    print(f\"Duration: {trace['duration_ms']}ms\")\n\n    for span in trace['spans']:\n        indent = \"  \" * span.get('level', 0)\n        print(f\"{indent}{span['name']} ({span['duration_ms']}ms)\")\n    ```\n\n**Response Format:**\n\n```json\n{\n  \"trace_id\": \"a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6\",\n  \"name\": \"GET /products\",\n  \"service_name\": \"demo-frontend\",\n  \"start_time\": 1701234567890000000,\n  \"duration_ms\": 125.4,\n  \"span_count\": 5,\n  \"spans\": [\n    {\n      \"span_id\": \"1234567890abcdef\",\n      \"parent_span_id\": null,\n      \"name\": \"GET /products\",\n      \"service_name\": \"demo-frontend\",\n      \"start_time\": 1701234567890000000,\n      \"duration_ms\": 125.4,\n      \"status\": { \"code\": 1 },\n      \"attributes\": {\n        \"http.method\": \"GET\",\n        \"http.route\": \"/products\",\n        \"http.status_code\": 200\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"api/#3-find-logs-for-a-specific-trace","title":"3. Find Logs for a Specific Trace","text":"<p>Correlate logs with a trace using trace_id:</p> cURL <p><code>bash     curl \"http://localhost:5005/api/logs?trace_id=a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6\"</code></p> Python <pre><code>import requests\n\n    trace_id = \"a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6\"\n    response = requests.get('http://localhost:5005/api/logs',\n                           params={'trace_id': trace_id})\n    logs = response.json()\n\n    for log in logs:\n        print(f\"[{log['severity']}] {log['body']}\")\n    ```\n\n**Response Format:**\n\n```json\n[\n  {\n    \"timestamp\": 1701234567890000000,\n    \"trace_id\": \"a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6\",\n    \"span_id\": \"1234567890abcdef\",\n    \"severity\": \"INFO\",\n    \"body\": \"Processing product request\",\n    \"service_name\": \"demo-frontend\",\n    \"attributes\": {\n      \"user_id\": \"12345\"\n    }\n  }\n]\n</code></pre>"},{"location":"api/#4-query-metrics","title":"4. Query Metrics","text":"<p>Retrieve metrics data:</p> cURL <p><code>bash     curl http://localhost:5005/api/metrics</code></p> Python <pre><code>import requests\n\n    response = requests.get('http://localhost:5005/api/metrics')\n    metrics = response.json()\n\n    for metric in metrics:\n        print(f\"{metric['name']} ({metric['type']})\")\n        for series in metric.get('series', []):\n            labels = ', '.join(f\"{k}={v}\" for k, v in series.get('attributes', {}).items())\n            print(f\"  [{labels}] = {series.get('value', 'N/A')}\")\n    ```\n\n**Response Format:**\n\n```json\n[\n  {\n    \"name\": \"http.server.duration\",\n    \"type\": \"histogram\",\n    \"description\": \"HTTP request duration\",\n    \"unit\": \"ms\",\n    \"series\": [\n      {\n        \"attributes\": {\n          \"http.method\": \"GET\",\n          \"http.route\": \"/products\",\n          \"service.name\": \"demo-frontend\"\n        },\n        \"data_points\": [\n          {\n            \"timestamp\": 1701234567890000000,\n            \"count\": 42,\n            \"sum\": 5250.5,\n            \"bucket_counts\": [10, 20, 10, 2]\n          }\n        ]\n      }\n    ]\n  }\n]\n</code></pre>"},{"location":"api/#5-get-service-catalog-with-red-metrics","title":"5. Get Service Catalog with RED Metrics","text":"<p>List all services with Rate, Errors, and Duration metrics:</p> cURL <p><code>bash     curl http://localhost:5005/api/service-catalog</code></p> Python <pre><code>import requests\n\n    response = requests.get('http://localhost:5005/api/service-catalog')\n    services = response.json()\n\n    for service in services:\n        print(f\"\\n{service['service_name']}\")\n        print(f\"  Request Rate: {service.get('request_rate', 0):.2f} req/s\")\n        print(f\"  Error Rate: {service.get('error_rate', 0):.2f}%\")\n        print(f\"  P50 Latency: {service.get('p50_latency', 0):.2f}ms\")\n        print(f\"  P95 Latency: {service.get('p95_latency', 0):.2f}ms\")\n    ```\n\n**Response Format:**\n\n```json\n[\n  {\n    \"service_name\": \"demo-frontend\",\n    \"span_count\": 1523,\n    \"request_rate\": 12.5,\n    \"error_rate\": 2.3,\n    \"p50_latency\": 45.2,\n    \"p95_latency\": 125.7,\n    \"p99_latency\": 250.3,\n    \"first_seen\": 1701234567890000000,\n    \"last_seen\": 1701238167890000000\n  }\n]\n</code></pre>"},{"location":"api/#6-get-service-dependency-map","title":"6. Get Service Dependency Map","text":"<p>Retrieve the service dependency graph:</p> cURL <p><code>bash     curl http://localhost:5005/api/service-map</code></p> Python <pre><code>import requests\n\n    response = requests.get('http://localhost:5005/api/service-map')\n    graph = response.json()\n\n    print(\"Services:\", len(graph['nodes']))\n    for node in graph['nodes']:\n        print(f\"  - {node['service_name']} ({node['type']})\")\n\n    print(\"\\nConnections:\", len(graph['edges']))\n    for edge in graph['edges']:\n        print(f\"  {edge['source']} \u2192 {edge['target']} ({edge['call_count']} calls)\")\n    ```\n\n**Response Format:**\n\n```json\n{\n  \"nodes\": [\n    {\n      \"service_name\": \"demo-frontend\",\n      \"type\": \"server\",\n      \"span_count\": 1523\n    },\n    {\n      \"service_name\": \"demo-backend\",\n      \"type\": \"server\",\n      \"span_count\": 3046\n    }\n  ],\n  \"edges\": [\n    {\n      \"source\": \"demo-frontend\",\n      \"target\": \"demo-backend\",\n      \"call_count\": 1523\n    }\n  ]\n}\n</code></pre>"},{"location":"api/#7-check-system-statistics","title":"7. Check System Statistics","text":"<p>Get Redis memory usage and cardinality metrics:</p> cURL <p><code>bash     curl http://localhost:5005/api/stats</code></p> Python <pre><code>import requests\n\n    response = requests.get('http://localhost:5005/api/stats')\n    stats = response.json()\n\n    print(f\"Total Traces: {stats.get('total_traces', 0)}\")\n    print(f\"Total Spans: {stats.get('total_spans', 0)}\")\n    print(f\"Total Logs: {stats.get('total_logs', 0)}\")\n    print(f\"Total Metrics: {stats.get('total_metrics', 0)}\")\n    print(f\"Unique Metric Names: {stats.get('unique_metric_names', 0)}\")\n    print(f\"Redis Memory: {stats.get('redis_memory_mb', 0):.2f} MB\")\n    ```\n\n**Response Format:**\n\n```json\n{\n  \"total_traces\": 1523,\n  \"total_spans\": 7615,\n  \"total_logs\": 15230,\n  \"total_metrics\": 45,\n  \"unique_metric_names\": 12,\n  \"redis_memory_mb\": 45.7,\n  \"cardinality_limit\": 1000,\n  \"cardinality_usage_pct\": 1.2,\n  \"uptime_seconds\": 3600\n}\n</code></pre>"},{"location":"api/#advanced-filtering","title":"Advanced Filtering","text":""},{"location":"api/#filter-spans-by-service","title":"Filter Spans by Service","text":"<pre><code>curl \"http://localhost:5005/api/spans?service=demo-frontend&amp;limit=100\"\n</code></pre>"},{"location":"api/#filter-logs-by-severity","title":"Filter Logs by Severity","text":"<pre><code>curl \"http://localhost:5005/api/logs?severity=ERROR&amp;limit=50\"\n</code></pre>"},{"location":"api/#time-based-queries","title":"Time-based Queries","text":"<p>All endpoints support <code>start_time</code> and <code>end_time</code> parameters (Unix nanoseconds):</p> <pre><code># Get traces from the last hour\nSTART=$(date -u -d '1 hour ago' +%s)000000000\nEND=$(date -u +%s)000000000\ncurl \"http://localhost:5005/api/traces?start_time=$START&amp;end_time=$END\"\n</code></pre>"},{"location":"api/#client-generation","title":"Client Generation","text":"<p>Generate API clients in any language using the OpenAPI spec:</p> <pre><code># Download OpenAPI spec\ncurl http://localhost:5005/openapi.json &gt; ollyscale-openapi.json\n\n# Generate Python client\nopenapi-generator-cli generate \\\n  -i ollyscale-openapi.json \\\n  -g python \\\n  -o ./ollyscale-python-client\n\n# Generate Go client\nopenapi-generator-cli generate \\\n  -i ollyscale-openapi.json \\\n  -g go \\\n  -o ./ollyscale-go-client\n\n# Generate TypeScript client\nopenapi-generator-cli generate \\\n  -i ollyscale-openapi.json \\\n  -g typescript-fetch \\\n  -o ./ollyscale-ts-client\n</code></pre>"},{"location":"api/#rate-limits","title":"Rate Limits","text":"<p>ollyScale is designed for local development and has no rate limits. However:</p> <ul> <li>Memory limits apply based on Redis configuration (default: 256MB)</li> <li>Cardinality protection limits unique metric names to 1000 (configurable)</li> <li>TTL: All data expires after 30 minutes</li> </ul>"},{"location":"api/#authentication","title":"Authentication","text":"<p>ollyScale is designed for local development and does not include authentication. Do not expose ollyScale to the internet without adding authentication via a reverse proxy.</p>"},{"location":"api/#need-help","title":"Need Help?","text":"<ul> <li>View interactive examples in Swagger UI</li> <li>Open an issue on GitHub</li> <li>Read the technical architecture</li> </ul>"},{"location":"build-system/","title":"ollyScale Build System - Deliverables &amp; Dependencies","text":"<p>Document Version: 2.1 Last Updated: January 15, 2026 Status: Active</p>"},{"location":"build-system/#overview","title":"Overview","text":"<p>This document maps ollyScale's deliverable artifacts and traces their build dependencies. We work backwards from what we ship to understand what needs to be built and in what order.</p> <p>Purpose:</p> <ul> <li>Identify what artifacts we publish to registries</li> <li>Understand rebuild requirements when source changes</li> <li>Optimize build order and minimize rebuilds</li> <li>Document the delivery pipeline</li> </ul>"},{"location":"build-system/#our-deliverables","title":"Our Deliverables","text":"<p>ollyScale produces two types of artifacts that are published to OCI registries:</p>"},{"location":"build-system/#1-oci-container-images-4-images","title":"1. OCI Container Images (4 images)","text":""},{"location":"build-system/#2-helm-charts-2-charts","title":"2. Helm Charts (2 charts)","text":"<p>All other scripts, configurations, and source code exist solely to produce these deliverables.</p>"},{"location":"build-system/#deliverable-1-oci-container-images","title":"Deliverable #1: OCI Container Images","text":"<p>We publish 4 container images to OCI-compatible registries:</p> <pre><code>DELIVERABLE: OCI Container Images\n\u251c\u2500 ollyscale/ollyscale          (Python backend - FastAPI + OTLP receiver)\n\u251c\u2500 ollyscale/webui             (Static frontend - nginx + TypeScript/Vite)\n\u251c\u2500 ollyscale/opamp-server      (OpAMP configuration server)\n\u2514\u2500 ollyscale/demo              (Demo application)\n</code></pre>"},{"location":"build-system/#image-ollyscaleollyscale","title":"Image: <code>ollyscale/ollyscale</code>","text":"<p>What it is: Python backend application that runs as either API server or OTLP receiver</p> <p>Published to:</p> <ul> <li>Production: <code>ghcr.io/ryanfaircloth/ollyscale/ollyscale:VERSION</code></li> <li>Local dev: <code>registry.ollyscale.test:49443/ollyscale/ollyscale:VERSION</code></li> </ul> <p>Run modes (controlled by <code>MODE</code> env var):</p> <ul> <li><code>MODE=ui</code> \u2192 FastAPI REST API server on port 5002</li> <li><code>MODE=receiver</code> \u2192 gRPC OTLP receiver on port 4343</li> </ul> <p>Built from:</p> <ul> <li>Dockerfile: <code>apps/ollyscale/Dockerfile</code></li> <li>Base image: <code>python:3.14-slim</code></li> <li>Source files (all from <code>apps/ollyscale/</code>):</li> <li><code>main.py</code> - Entry point that selects mode</li> <li><code>models.py</code> - Pydantic data models</li> <li><code>requirements.txt</code> - Python dependencies</li> <li><code>app/</code> - FastAPI routers and API endpoints</li> <li><code>receiver/</code> - gRPC receiver for receiver mode</li> <li><code>common/</code> - Shared utilities (storage, OTLP parsing) docker buildx build --platform linux/amd64,linux/arm64 \\   -f apps/ollyscale/Dockerfile \\   -t ghcr.io/ryanfaircloth/ollyscale/ollyscale:v2.1.8 \\   --push apps/ollyscale/</li> </ul>"},{"location":"build-system/#local-dev-single-arch","title":"Local dev (single-arch)","text":"<p>podman build -f apps/ollyscale/Dockerfile \\   -t registry.ollyscale.test:49443/ollyscale/ollyscale:v2.1.x-feature \\   apps/ollyscale/ <pre><code>**Rebuild triggers**:\n\n- Change to any file in `apps/ollyscale/`\n- Change to `requirements.txt`\n- Change to Dockerfile\n\n---\n\n### Image: `ollyscale/webui`\n\n**What it is**: Static web frontend served by nginx\n\n**Published to**:\n\n- Production: `ghcr.io/ryanfaircloth/ollyscale/webui:VERSION`\n- Local dev: `registry.ollyscale.test:49443/ollyscale/webui:VERSION`\n\n**Functionality**:\n\n- TypeScript/Vite SPA with modern build tooling\n- Served by nginx on port 80\n- Connects to backend API at `/api/*`\n\n**Built from**:\n\n- **Dockerfile**: `apps/ollyscale-ui/Dockerfile`\n- **Base image**: `node:20-alpine` (build), `nginx:alpine` (runtime)\n- **Source files** (from `apps/ollyscale-ui/`):\n  - `src/` - TypeScript modules and main entry point\n  - `src/modules/` - API client, traces, serviceMap, metrics, etc.\n  - `index.html` - HTML template\n  - `vite.config.js` - Vite build configuration\n  - `package.json` - NPM dependencies\n  - `nginx/` - nginx configuration\n\n**Build command**:\n\n```bash\n# Production (multi-arch)\ndocker buildx build --platform linux/amd64,linux/arm64 \\\n  -f apps/ollyscale-ui/Dockerfile \\\n  -t ghcr.io/ryanfaircloth/ollyscale/webui:v2.1.8 \\\n  --push apps/ollyscale-ui/\n\n# Local dev (single-arch)\npodman build -f apps/ollyscale-ui/Dockerfile \\\n  -t registry.ollyscale.test:49443/ollyscale/webui:v2.1.x-feature \\\n  apps/ollyscale-ui/\n</code></pre></p> <p>Rebuild triggers:</p> <ul> <li>Change to any file in <code>apps/ollyscale-ui/src/</code></li> <li>Change to <code>package.json</code></li> <li>Change to Dockerfile</li> <li>Change to nginx configuration</li> </ul>"},{"location":"build-system/#image-ollyscaleopamp-server","title":"Image: <code>ollyscale/opamp-server</code>","text":"<p>What it is: OpAMP server for remote OpenTelemetry Collector configuration</p> <p>Published to:</p> <ul> <li>Production: <code>ghcr.io/ryanfaircloth/ollyscale/opamp-server:VERSION</code></li> <li>Local dev: <code>registry.ollyscale.test:49443/ollyscale/opamp-server:VERSION</code></li> </ul> <p>Functionality:</p> <ul> <li>OpAMP protocol endpoint on port 4320</li> <li>REST API for config management on port 4321</li> </ul> <p>Built from:</p> <ul> <li>Dockerfile: <code>apps/opamp-server/Dockerfile</code></li> <li>Base image: <code>golang:1.25-alpine</code> (build), <code>scratch</code> (runtime)</li> <li>Source files (from <code>apps/opamp-server/</code>):</li> <li><code>main.go</code> - OpAMP server implementation</li> <li><code>go.mod</code> - Go module definition</li> </ul> <p>Build command:</p> <pre><code># Production (multi-arch)\ndocker buildx build --platform linux/amd64,linux/arm64 \\\n  -f apps/opamp-server/Dockerfile \\\n  -t ghcr.io/ryanfaircloth/ollyscale/opamp-server:v2.1.8 \\\n  --push apps/opamp-server/\n\n# Local dev (single-arch)\npodman build -f apps/opamp-server/Dockerfile \\\n  -t registry.ollyscale.test:49443/ollyscale/opamp-server:v2.1.x-feature \\\n  apps/opamp-server/\n</code></pre> <p>Rebuild triggers:</p> <ul> <li>Change to <code>main.go</code></li> <li>Change to <code>go.mod</code></li> <li>Change to Dockerfile</li> </ul>"},{"location":"build-system/#image-ollyscaledemo","title":"Image: <code>ollyscale/demo</code>","text":"<p>What it is: Unified demo application with frontend and backend</p> <p>Published to:</p> <ul> <li>Production: <code>ghcr.io/ryanfaircloth/ollyscale/demo:VERSION</code></li> <li>Local dev: <code>registry.ollyscale.test:49443/ollyscale/demo:VERSION</code></li> </ul> <p>Functionality:</p> <ul> <li>Generates sample traces, logs, and metrics</li> <li>Can run as frontend or backend via <code>MODE</code> env var</li> </ul> <p>Built from:</p> <ul> <li>Dockerfile: <code>apps/demo/Dockerfile</code></li> <li>Base image: <code>python:3.12-slim</code></li> <li>Source files (from <code>apps/demo/</code>):</li> <li><code>frontend.py</code> - Demo frontend service</li> <li><code>backend.py</code> - Demo backend service</li> <li><code>requirements.txt</code> - Python dependencies</li> </ul> <p>Build command:</p> <pre><code># Production (multi-arch)\ndocker buildx build --platform linux/amd64,linux/arm64 \\\n  -f apps/demo/Dockerfile \\\n  -t ghcr.io/ryanfaircloth/ollyscale/demo:v2.1.8 \\\n  --push apps/demo/\n\n# Local dev (single-arch)\npodman build -f apps/demo/Dockerfile \\\n  -t registry.ollyscale.test:49443/ollyscale/demo:v2.1.x-feature \\\n  apps/demo/\n</code></pre> <p>Rebuild triggers:</p> <ul> <li>Change to <code>frontend.py</code> or <code>backend.py</code></li> <li>Change to <code>requirements.txt</code></li> <li>Change to Dockerfile</li> </ul>"},{"location":"build-system/#deliverable-2-helm-charts","title":"Deliverable #2: Helm Charts","text":"<p>We publish 2 Helm charts to OCI registries:</p> <pre><code>DELIVERABLE: Helm Charts (OCI format)\n\u251c\u2500 ollyscale              (Main platform chart)\n\u2514\u2500 ollyscale-demos        (Demo applications chart)\n</code></pre>"},{"location":"build-system/#chart-ollyscale","title":"Chart: <code>ollyscale</code>","text":"<p>What it is: Complete ollyScale platform deployment</p> <p>Published to:</p> <ul> <li>Production: <code>oci://ghcr.io/ryanfaircloth/ollyscale/charts/ollyscale:VERSION</code></li> <li>Local dev: <code>oci://registry.ollyscale.test:49443/ollyscale/charts/ollyscale:VERSION</code></li> </ul> <p>Contains:</p> <ul> <li>Backend API deployment (uses <code>ollyscale/ollyscale:VERSION</code> with <code>MODE=ui</code>)</li> <li>Frontend webui deployment (uses <code>ollyscale/webui:VERSION</code>)</li> <li>OTLP receiver deployment (uses <code>ollyscale/ollyscale:VERSION</code> with <code>MODE=receiver</code>)</li> <li>OpAMP server deployment (uses <code>ollyscale/opamp-server:VERSION</code>)</li> <li>Redis StatefulSet</li> <li>OTel Collector DaemonSet (optional)</li> <li>OpenTelemetry Instrumentation CRs (optional)</li> <li>Services, ConfigMaps, Secrets</li> </ul> <p>Built from:</p> <ul> <li>Chart location: <code>charts/ollyscale/</code></li> <li>Chart.yaml: Metadata and version</li> <li>values.yaml: Default configuration</li> <li>templates/: Kubernetes manifests</li> <li><code>webui-deployment.yaml</code></li> <li><code>frontend-deployment.yaml</code></li> <li><code>otlp-receiver-deployment.yaml</code></li> <li><code>opamp-server-deployment.yaml</code></li> <li><code>redis-statefulset.yaml</code></li> <li><code>otelcol-daemonset.yaml</code></li> <li><code>instrumentation.yaml</code></li> <li><code>service-*.yaml</code></li> <li><code>configmap-*.yaml</code></li> </ul> <p>Dependencies:</p> <ul> <li>Requires container images to exist:</li> <li><code>ollyscale/webui:VERSION</code></li> <li><code>ollyscale/ollyscale:VERSION</code></li> <li><code>ollyscale/opamp-server:VERSION</code></li> <li>May reference external charts (Redis Operator, OTel Operator)</li> </ul> <p>Build command:</p> <pre><code># Package chart\nhelm package charts/ollyscale/ -d charts/\n\n# Push to OCI registry\nhelm push charts/ollyscale-0.1.1-v2.1.x-feature.tgz \\\n  oci://registry.ollyscale.test:49443/ollyscale/charts\n</code></pre> <p>Version format:</p> <ul> <li>Production: <code>0.1.1</code> (semantic version)</li> <li>Local dev: <code>0.1.1-v2.1.x-description</code></li> </ul> <p>Rebuild triggers:</p> <ul> <li>Change to any file in <code>charts/ollyscale/templates/</code></li> <li>Change to <code>values.yaml</code></li> <li>Change to <code>Chart.yaml</code></li> <li>New container image version (update <code>appVersion</code>)</li> </ul>"},{"location":"build-system/#chart-ollyscale-demos","title":"Chart: <code>ollyscale-demos</code>","text":"<p>What it is: Demo applications for ollyScale</p> <p>Published to:</p> <ul> <li>Production: <code>oci://ghcr.io/ryanfaircloth/ollyscale/charts/ollyscale-demos:VERSION</code></li> <li>Local dev: <code>oci://registry.ollyscale.test:49443/ollyscale/charts/ollyscale-demos:VERSION</code></li> </ul> <p>Contains:</p> <ul> <li>Demo frontend deployment (uses <code>ollyscale/demo:VERSION</code> with <code>MODE=frontend</code>)</li> <li>Demo backend deployment (uses <code>ollyscale/demo:VERSION</code> with <code>MODE=backend</code>)</li> <li>Traffic generator (optional)</li> <li>Services to wire frontend \u2192 backend</li> </ul> <p>Built from:</p> <ul> <li>Chart location: <code>charts/ollyscale-demos/</code></li> <li>Chart.yaml: Metadata and version</li> <li>values.yaml: Demo configuration</li> <li>templates/: Kubernetes manifests</li> <li><code>deployment-frontend.yaml</code></li> <li><code>deployment-backend.yaml</code></li> <li><code>job-traffic-generator.yaml</code></li> <li><code>service-*.yaml</code></li> </ul> <p>Dependencies:</p> <ul> <li>Requires container image: <code>ollyscale/demo:VERSION</code></li> <li>Expects <code>ollyscale</code> chart to be deployed (for OTLP endpoint)</li> </ul> <p>Build command:</p> <pre><code># Package chart\nhelm package charts/ollyscale-demos/ -d charts/\n\n# Push to OCI registry\nhelm push charts/ollyscale-demos-0.1.5.tgz \\\n  oci://registry.ollyscale.test:49443/ollyscale/charts\n</code></pre> <p>Rebuild triggers:</p> <ul> <li>Change to any file in <code>charts/ollyscale-demos/templates/</code></li> <li>Change to <code>values.yaml</code></li> <li>Change to <code>Chart.yaml</code></li> <li>New demo image version</li> </ul>"},{"location":"build-system/#dependency-graph-backwards-from-deliverables","title":"Dependency Graph (Backwards from Deliverables)","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    DELIVERABLE ARTIFACTS                        \u2502\n\u2502                  (What we publish to registries)                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                \u2502\n                \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                \u2502                               \u2502\n                \u25bc                               \u25bc\n     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n     \u2502  OCI IMAGES (3)   \u2502           \u2502  HELM CHARTS (2)  \u2502\n     \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524           \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n     \u2502 1. ollyscale       \u2502           \u2502 1. ollyscale       \u2502\n     \u2502 2. opamp-server   \u2502           \u2502 2. ollyscale-demos \u2502\n     \u2502 3. demo           \u2502           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                     \u2502\n               \u2502                               \u2502\n               \u2502          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2502          \u2502\n               \u25bc          \u25bc\n     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n     \u2502              BUILD INPUTS                           \u2502\n     \u2502          (Dockerfiles + Source Code)                \u2502\n     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2502\n               \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n               \u2502                                     \u2502\n               \u25bc                                     \u25bc\n     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n     \u2502  apps/ollyscale/     \u2502            \u2502 Chart.yaml          \u2502\n     \u2502  Dockerfile         \u2502            \u2502 values.yaml         \u2502\n     \u2502       +             \u2502            \u2502 templates/*.yaml    \u2502\n     \u2502  \u251c\u2500 main.py         \u2502            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502  \u251c\u2500 models.py       \u2502                     \u25b2\n     \u2502  \u251c\u2500 requirements.txt\u2502                     \u2502\n     \u2502  \u251c\u2500 app/            \u2502                     \u2502\n     \u2502  \u251c\u2500 receiver/       \u2502            (Helm charts reference)\n     \u2502  \u251c\u2500 common/         \u2502            (image tags from above)\n     \u2502  \u251c\u2500 static/         \u2502\n     \u2502  \u2514\u2500 templates/      \u2502\n     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Key relationships:</p> <ol> <li>Helm charts depend on container images - Charts reference image tags</li> <li>Container images depend on source code - Dockerfiles copy source into images</li> <li>Charts must be rebuilt when image versions change (update <code>appVersion</code>)</li> </ol>"},{"location":"build-system/#build-scripts-by-target","title":"Build Scripts by Target","text":""},{"location":"build-system/#production-builds-ghcr-multi-platform","title":"Production Builds \u2192 GHCR (Multi-platform)","text":"<p>Location: <code>scripts/build/</code> Registry: <code>ghcr.io/ryanfaircloth/ollyscale/*</code> Platforms: <code>linux/amd64</code>, <code>linux/arm64</code></p> Script Builds Command <code>02-build-core.sh VERSION</code> ollyscale:VERSIONwebui:VERSIONopamp-server:VERSION Uses Docker BuildxMulti-platform <code>02-build-demo.sh VERSION</code> demo:VERSION Uses Docker BuildxMulti-platform <code>02-build-all.sh VERSION</code> All images above Calls other scripts <code>03-push-core.sh VERSION</code> N/A - pushes only Pushes to GHCR <code>03-push-demo.sh VERSION</code> N/A - pushes only Pushes to GHCR <code>03-push-all.sh VERSION</code> N/A - pushes only Pushes all to GHCR <p>Typical workflow:</p> <pre><code>cd scripts/build\n./02-build-all.sh v2.1.8    # Build all images (multi-arch)\n./03-push-all.sh v2.1.8     # Push to ghcr.io\n</code></pre> <p>Chart publishing (separate process):</p> <pre><code>cd charts\n./package.sh                # Package charts\n./push-oci.sh               # Push to public registry\n</code></pre>"},{"location":"build-system/#local-development-builds-local-registry-single-platform","title":"Local Development Builds \u2192 Local Registry (Single-platform)","text":"<p>Location: <code>charts/</code> Registry: <code>registry.ollyscale.test:49443/ollyscale/*</code> Platforms: Native only (faster builds)</p> Script Builds Description <code>build-and-push-local.sh VERSION</code> 1. All 4 container images2. ollyscale Helm chart Complete pipeline:- Build images- Push to local registry- Update Chart.yaml- Package chart- Push chart to OCI <p>What it does:</p> <pre><code># Example: ./build-and-push-local.sh v2.1.x-tail-sampling\n\n# Step 1: Build images\npodman build -f apps/ollyscale/Dockerfile \\\n  -t registry.ollyscale.test:49443/ollyscale/ollyscale:v2.1.x-tail-sampling \\\n  apps/ollyscale/\n\npodman build -f apps/ollyscale-ui/Dockerfile \\\n  -t registry.ollyscale.test:49443/ollyscale/webui:v2.1.x-tail-sampling \\\n  apps/ollyscale-ui/\n\npodman build -f apps/opamp-server/Dockerfile \\\n  -t registry.ollyscale.test:49443/ollyscale/opamp-server:v2.1.x-tail-sampling \\\n  apps/opamp-server/\n\npodman build -f apps/demo/Dockerfile \\\n  -t registry.ollyscale.test:49443/ollyscale/demo:v2.1.x-tail-sampling \\\n  apps/demo/\n\n# Step 2: Push images to local registry (external endpoint)\npodman push --tls-verify=false registry.ollyscale.test:49443/ollyscale/ollyscale:v2.1.x-tail-sampling\n# ... (webui, opamp-server, demo)\n\n# Step 3: Update Chart.yaml version\nsed -i '' \"s/^version: .*/version: 0.1.1-v2.1.x-tail-sampling/\" charts/ollyscale/Chart.yaml\n\n# Step 4: Generate values-local-dev.yaml with INTERNAL registry\ncat &gt; values-local-dev.yaml &lt;&lt;EOF\nui:\n  image:\n    repository: docker-registry.registry.svc.cluster.local:5000/ollyscale/ollyscale\n    tag: v2.1.x-tail-sampling\nwebui:\n  image:\n    repository: docker-registry.registry.svc.cluster.local:5000/ollyscale/webui\n    tag: v2.1.x-tail-sampling\n# ... etc\nEOF\n\n# Step 5: Package chart\nhelm package charts/ollyscale/ -d charts/\n\n# Step 6: Push chart to OCI registry\nhelm push charts/ollyscale-0.1.1-v2.1.x-tail-sampling.tgz \\\n  oci://registry.ollyscale.test:49443/ollyscale/charts\n</code></pre> <p>Deploy to cluster:</p> <pre><code># Update ArgoCD Application to use new chart version\ncd .kind\nterraform apply -replace='kubectl_manifest.observability_applications[\"observability/ollyscale.yaml\"]' -auto-approve\n</code></pre>"},{"location":"build-system/#deprecated-scripts-do-not-use","title":"Deprecated Scripts (Do Not Use)","text":"<p>These scripts are no longer maintained and should not be used:</p> Status Replacement Notes \ud83d\uddd1\ufe0f Removed <code>charts/build-and-push-local.sh</code> Old k8s/ scripts deleted \ud83d\uddd1\ufe0f Removed ArgoCD + Terraform pattern GitOps deployment recommended"},{"location":"build-system/#registry-endpoints-critical","title":"Registry Endpoints (Critical!)","text":"<p>ollyScale uses different registry endpoints for build/push vs runtime deployment. This is a common source of confusion.</p>"},{"location":"build-system/#the-same-physical-registry-different-access-points","title":"The Same Physical Registry, Different Access Points","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          LOCAL KUBERNETES CLUSTER REGISTRY                   \u2502\n\u2502                  (One registry pod)                          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502                  \u2502                  \u2502\n        \u25bc                  \u25bc                  \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  EXTERNAL    \u2502  \u2502   NODEPORT   \u2502  \u2502   INTERNAL   \u2502\n\u2502  (Build)     \u2502  \u2502  (Alt Build) \u2502  \u2502  (Runtime)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 registry.    \u2502  \u2502 localhost:   \u2502  \u2502 docker-      \u2502\n\u2502 ollyscale.    \u2502  \u2502 30500        \u2502  \u2502 registry.    \u2502\n\u2502 test:49443   \u2502  \u2502              \u2502  \u2502 registry.svc \u2502\n\u2502              \u2502  \u2502              \u2502  \u2502 .cluster.    \u2502\n\u2502              \u2502  \u2502              \u2502  \u2502 local:5000   \u2502\n\u2502              \u2502  \u2502              \u2502  \u2502              \u2502\n\u2502 Use: podman  \u2502  \u2502 Use: podman  \u2502  \u2502 Use: K8s pod \u2502\n\u2502 push from    \u2502  \u2502 push from    \u2502  \u2502 image pull   \u2502\n\u2502 desktop      \u2502  \u2502 desktop      \u2502  \u2502              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Rules:</p> <ol> <li>Build scripts push to <code>registry.ollyscale.test:49443</code> (external endpoint)</li> <li>Helm values reference <code>docker-registry.registry.svc.cluster.local:5000</code> (internal endpoint)</li> <li>Never use <code>registry.ollyscale.test:49443</code> in pod image specs - cluster can't resolve it!</li> </ol> <p>Example (<code>values-local-dev.yaml</code>):</p> <pre><code># \u2705 CORRECT - internal endpoint for cluster\nui:\n  image:\n    repository: docker-registry.registry.svc.cluster.local:5000/ollyscale/ollyscale\n    tag: v2.1.x-feature\n\n# \u274c WRONG - external endpoint, pods can't pull\nui:\n  image:\n    repository: registry.ollyscale.test:49443/ollyscale/ollyscale\n    tag: v2.1.x-feature\n</code></pre>"},{"location":"build-system/#production-registry-ghcr","title":"Production Registry (GHCR)","text":"<p>Endpoint: <code>ghcr.io/ryanfaircloth/ollyscale/*</code> Access: Public (read), authenticated (write) Usage: Production releases only</p>"},{"location":"build-system/#complete-dependency-matrix","title":"Complete Dependency Matrix","text":""},{"location":"build-system/#what-triggers-what","title":"What Triggers What?","text":"Change Type Requires Rebuild Deployment Action Source Code <code>apps/ollyscale/app/</code> <code>ollyscale:VERSION</code> image Rebuild image \u2192 Update chart \u2192 Deploy <code>apps/ollyscale/receiver/</code> <code>ollyscale:VERSION</code> image Rebuild image \u2192 Update chart \u2192 Deploy <code>apps/ollyscale/requirements.txt</code> <code>ollyscale:VERSION</code> image Rebuild image \u2192 Update chart \u2192 Deploy <code>apps/ollyscale-ui/src/</code> <code>webui:VERSION</code> image Rebuild image \u2192 Update chart \u2192 Deploy <code>apps/ollyscale-ui/package.json</code> <code>webui:VERSION</code> image Rebuild image \u2192 Update chart \u2192 Deploy <code>apps/opamp-server/</code> <code>opamp-server:VERSION</code> image Rebuild image \u2192 Update chart \u2192 Deploy <code>apps/demo/frontend.py</code> <code>demo:VERSION</code> image Rebuild image \u2192 Update demos chart \u2192 Deploy <code>apps/demo/backend.py</code> <code>demo:VERSION</code> image Rebuild image \u2192 Update demos chart \u2192 Deploy Dockerfiles <code>apps/ollyscale/Dockerfile</code> <code>ollyscale:VERSION</code> image Rebuild image \u2192 Update chart \u2192 Deploy <code>apps/ollyscale-ui/Dockerfile</code> <code>webui:VERSION</code> image Rebuild image \u2192 Update chart \u2192 Deploy <code>apps/opamp-server/Dockerfile</code> <code>opamp-server:VERSION</code> image Rebuild image \u2192 Update chart \u2192 Deploy <code>apps/demo/Dockerfile</code> <code>demo:VERSION</code> image Rebuild image \u2192 Update demos chart \u2192 Deploy Helm Charts <code>charts/ollyscale/templates/</code> <code>ollyscale</code> chart Package chart \u2192 Deploy <code>charts/ollyscale/values.yaml</code> <code>ollyscale</code> chart Package chart \u2192 Deploy <code>charts/ollyscale/Chart.yaml</code> <code>ollyscale</code> chart Package chart \u2192 Deploy <code>charts/ollyscale-demos/templates/</code> <code>ollyscale-demos</code> chart Package chart \u2192 Deploy Deployment <code>.kind/modules/main/argocd-applications/</code> None (config only) <code>terraform apply</code>"},{"location":"build-system/#build-optimization-opportunities","title":"Build Optimization Opportunities","text":""},{"location":"build-system/#current-issues","title":"Current Issues","text":"<ol> <li>No shared base image: <code>ollyscale</code> image rebuilds all Python deps on every build</li> <li>No build caching: Production builds use <code>--no-cache</code> flag</li> <li>Dockerfile redundancy: Demo images duplicate patterns from main image</li> <li>Version coordination: Chart version and image tags updated manually</li> </ol>"},{"location":"build-system/#improvement-proposals","title":"Improvement Proposals","text":""},{"location":"build-system/#1-create-python-base-image","title":"1. Create Python Base Image","text":"<pre><code># NEW: Dockerfile.ollyscale-python-base\nFROM python:3.14-slim\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n# Tag: ollyscale/python-base:v2.1\n</code></pre> <p>Then update <code>Dockerfile.ollyscale</code>:</p> <pre><code>FROM ollyscale/python-base:v2.1  # \u2190 Use base\n# Only copy app code, deps already installed\n</code></pre> <p>Benefit: Faster builds when only code changes (not deps)</p>"},{"location":"build-system/#2-enable-build-caching-for-local-builds","title":"2. Enable Build Caching for Local Builds","text":"<pre><code># Remove --no-cache flag from build scripts\ndocker buildx build ... # (no --no-cache)\n</code></pre> <p>Benefit: 5-10x faster iteration on small changes</p>"},{"location":"build-system/#3-single-multi-stage-dockerfile","title":"3. Single Multi-stage Dockerfile","text":"<p>Combine all demo variants into one Dockerfile:</p> <pre><code># Dockerfile.demo - unified\nFROM python:3.12-slim AS base\n# ... shared setup ...\n\nFROM base AS frontend\nCOPY frontend.py .\nCMD [\"python\", \"frontend.py\"]\n\nFROM base AS backend\nCOPY backend.py .\nCMD [\"python\", \"backend.py\"]\n</code></pre> <p>Benefit: DRY, easier to maintain</p>"},{"location":"build-system/#4-automated-version-management","title":"4. Automated Version Management","text":"<pre><code># Extract version from git tag or commit\nVERSION=$(git describe --tags --always)\n# Auto-update Chart.yaml appVersion\nyq eval \".appVersion = \\\"$VERSION\\\"\" -i Chart.yaml\n</code></pre> <p>Benefit: Eliminate manual version sync errors</p>"},{"location":"build-system/#quick-reference-build-commands","title":"Quick Reference: Build Commands","text":""},{"location":"build-system/#local-development-common-case","title":"Local Development (Common Case)","text":"<pre><code># From repo root\ncd charts\n./build-and-push-local.sh v2.1.x-description\n\n# Deploy to cluster\ncd ../.kind\nterraform apply -replace='kubectl_manifest.observability_applications[\"observability/ollyscale.yaml\"]' -auto-approve\n\n# Verify deployment\nkubectl get pods -n ollyscale\nkubectl logs -n ollyscale deployment/ollyscale-ui -f\n\n# Clear cache if needed\nkubectl exec -n ollyscale ollyscale-redis-0 -- redis-cli FLUSHDB\n</code></pre>"},{"location":"build-system/#production-release","title":"Production Release","text":"<pre><code># Build and push images\ncd scripts/build\n./02-build-all.sh v2.1.8\n./03-push-all.sh v2.1.8\n\n# Package and publish charts\ncd ../../helm\n./package.sh\n./push-oci.sh\n\n# Tag release\ngit tag -a v2.1.8 -m \"Release v2.1.8\"\ngit push origin v2.1.8\n</code></pre>"},{"location":"build-system/#quick-image-only-rebuild-local","title":"Quick Image-Only Rebuild (Local)","text":"<pre><code># When you ONLY changed ollyscale source code\ncd /repo/root/docker\npodman build -f dockerfiles/Dockerfile.ollyscale \\\n  -t registry.ollyscale.test:49443/ollyscale/ollyscale:v2.1.x-hotfix .\npodman push --tls-verify=false \\\n  registry.ollyscale.test:49443/ollyscale/ollyscale:v2.1.x-hotfix\n\n# Update just the image tag in ArgoCD\nkubectl -n argocd patch application ollyscale --type merge \\\n  -p '{\"spec\":{\"source\":{\"helm\":{\"valuesObject\":{\"ui\":{\"image\":{\"tag\":\"v2.1.x-hotfix\"}}}}}}}'\n</code></pre>"},{"location":"build-system/#summary-the-build-system-in-one-diagram","title":"Summary: The Build System in One Diagram","text":"<pre><code>SOURCE CODE                    BUILD ARTIFACTS                 REGISTRIES\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500              \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\ndocker/apps/\nollyscale/          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6   ollyscale/ollyscale    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6 ghcr.io/...\n  (Python)                     (OCI image)                    (production)\n\ndocker/apps/                                                  registry.\nollyscale-opamp-    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6   ollyscale/opamp-      \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6 ollyscale.test\nserver/ (Go)                   server (OCI image)             (local dev)\n\napps/demo/       \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6   ollyscale/demo        \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\n  (Python)                     (OCI image)\n                                      \u2502\n                                      \u2502 (referenced by)\n                                      \u25bc\ncharts/ollyscale/     \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6   ollyscale             \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6 OCI registry\n  (K8s manifests)              (Helm chart .tgz)              /charts\n\ncharts/ollyscale-     \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6   ollyscale-demos       \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6 OCI registry\ndemos/                         (Helm chart .tgz)              /charts\n\n\nTOOLS USED:\n- podman/docker buildx  \u2192  Build OCI images\n- helm package          \u2192  Package charts\n- helm push            \u2192  Publish to OCI registry\n- ArgoCD + Terraform   \u2192  Deploy to Kubernetes\n</code></pre> <p>Key Insight: We ship 5 artifacts total:</p> <ul> <li>3 container images (ollyscale, opamp-server, demo)</li> <li>2 Helm charts (ollyscale, ollyscale-demos)</li> </ul>"},{"location":"build-system/#document-maintenance","title":"Document Maintenance","text":"<p>This document should be updated when:</p> <ul> <li>New container images are added</li> <li>New Helm charts are created</li> <li>Build scripts are added/removed/renamed</li> <li>Deployment workflow changes</li> <li>Registry endpoints change</li> <li>New dependencies are introduced</li> </ul> <p>Owner: Infrastructure Team Review Frequency: On major releases or build system changes</p>"},{"location":"ebpf/","title":"eBPF Zero-Code Tracing Demo","text":"<p>This demo showcases OpenTelemetry eBPF Instrumentation (OBI) - automatic trace capture at the kernel level without any code changes to your application.</p>"},{"location":"ebpf/#platform-requirements","title":"\u26a0\ufe0f Platform Requirements","text":"<p>Important: eBPF instrumentation requires a real Linux kernel and will NOT work in virtualized or emulated environments:</p> <p>\u2705 Supported Platforms:</p> <ul> <li>Native Linux Kubernetes clusters (GKE, EKS, AKS, bare-metal)</li> <li>Linux kernel 5.11 or newer</li> <li>Real hardware or KVM-based VMs</li> </ul> <p>\u274c Unsupported Platforms (will fail with memlock errors):</p> <ul> <li>KIND clusters on macOS/Windows</li> <li>Docker Desktop on macOS/Windows</li> <li>Podman on macOS</li> <li>Minikube with Docker driver on macOS/Windows</li> <li>Any Docker-in-Docker or VM-based Kubernetes</li> </ul> <p>For Local Development: Use the OpenTelemetry Operator auto-instrumentation feature instead, which works on all platforms by injecting SDK instrumentation at runtime.</p>"},{"location":"ebpf/#what-is-obi","title":"What is OBI?","text":"<p>OpenTelemetry eBPF Instrumentation (formerly Grafana Beyla) uses eBPF to automatically capture HTTP/gRPC traces by inspecting system calls and network traffic at the Linux kernel level.</p> <p>Key Benefits:</p> <ul> <li>Zero code changes - no SDK, no agent, no restarts</li> <li>Language agnostic - works with Python, Go, Java, Node.js, Rust, C, PHP, and more</li> <li>Protocol-level instrumentation - captures any HTTP/gRPC traffic</li> </ul>"},{"location":"ebpf/#quick-start","title":"Quick Start","text":""},{"location":"ebpf/#docker","title":"Docker","text":"<pre><code># Start ollyScale core first\ncd docker\n./01-start-core.sh\n\n# Deploy eBPF demo (pulls pre-built images from Docker Hub)\ncd ../apps/demo-ebpf\n./01-deploy-ebpf-demo.sh\n</code></pre> <p>Access the UI at <code>http://localhost:5005</code></p>"},{"location":"ebpf/#kubernetes","title":"Kubernetes","text":"<pre><code># Start ollyScale core first\nminikube start\ncd charts\n./install.sh\n\n# Deploy eBPF demo (pulls pre-built images from Docker Hub)\ncd ../k8s-demo-ebpf\n./02-deploy.sh\n</code></pre> <p>Run <code>minikube tunnel</code> in a separate terminal, then access the UI at <code>http://localhost:5002</code></p>"},{"location":"ebpf/#docker-hub-images","title":"Docker Hub Images","text":"<p>The eBPF demo uses pre-built images from Docker Hub:</p> <ul> <li><code>ghcr.io/ryanfaircloth/ebpf-frontend:latest</code> - Frontend with OTel SDK for metrics/logs</li> <li><code>ghcr.io/ryanfaircloth/ebpf-backend:latest</code> - Pure Flask backend (no OTel SDK)</li> </ul> <p>For local development, use the build scripts in each demo folder.</p>"},{"location":"ebpf/#whats-different-from-sdk-instrumentation","title":"What's Different from SDK Instrumentation?","text":""},{"location":"ebpf/#traces","title":"Traces","text":"Aspect SDK Instrumentation eBPF Instrumentation Span names Route names (<code>GET /hello</code>, <code>POST /api/users</code>) Generic (<code>in queue</code>, <code>CONNECT</code>, <code>HTTP</code>) Span attributes Rich application context (user IDs, request params) Network-level only (host, port, method) Distributed tracing Full trace propagation via headers Limited - eBPF sees connections, not header context Setup Code changes or auto-instrumentation wrapper Deploy eBPF agent alongside app <p>Example - SDK trace:</p> <pre><code>{\n  \"trace_id\": \"abc123...\",\n  \"span_name\": \"GET /process-order\",\n  \"attributes\": {\n    \"http.method\": \"GET\",\n    \"http.route\": \"/process-order\",\n    \"http.status_code\": 200,\n    \"order.id\": \"12345\",\n    \"customer.id\": \"678\"\n  }\n}\n</code></pre> <p>Example - eBPF trace:</p> <pre><code>{\n  \"trace_id\": \"def456...\",\n  \"span_name\": \"in queue\",\n  \"attributes\": {\n    \"net.host.name\": \"ebpf-frontend\",\n    \"net.host.port\": 5000\n  }\n}\n</code></pre>"},{"location":"ebpf/#logs","title":"Logs","text":"<p>With SDK instrumentation, logs include trace context (<code>trace_id</code>, <code>span_id</code>) for correlation:</p> <pre><code>{\n  \"message\": \"Processing order 12345\",\n  \"trace_id\": \"abc123...\",\n  \"span_id\": \"xyz789...\"\n}\n</code></pre> <p>With eBPF instrumentation, logs have no trace context because there's no tracing SDK to inject it:</p> <pre><code>{\n  \"message\": \"Processing order 12345\",\n  \"trace_id\": \"\",\n  \"span_id\": \"\"\n}\n</code></pre> <p>This is expected behavior - eBPF operates at the kernel level and cannot inject context into application logs.</p>"},{"location":"ebpf/#metrics","title":"Metrics","text":"<p>Metrics work the same way in both approaches - they're exported via the OTel SDK regardless of how traces are captured.</p>"},{"location":"ebpf/#components","title":"Components","text":""},{"location":"ebpf/#frontend-ebpf-frontend","title":"Frontend (<code>ebpf-frontend</code>)","text":"<ul> <li>Flask application with auto-traffic generation</li> <li>Metrics: Exported via OTel SDK (<code>OTLPMetricExporter</code>)</li> <li>Logs: Exported via OTel SDK (<code>OTLPLogExporter</code>)</li> <li>Traces: None from SDK - captured by eBPF agent</li> </ul>"},{"location":"ebpf/#backend-ebpf-backend","title":"Backend (<code>ebpf-backend</code>)","text":"<ul> <li>Pure Flask application - no OTel SDK at all</li> <li>Demonstrates that eBPF can trace completely uninstrumented apps</li> <li>Logs go to stdout only (not exported to OTel)</li> </ul>"},{"location":"ebpf/#ebpf-agent-otel-ebpf-agent","title":"eBPF Agent (<code>otel-ebpf-agent</code>)","text":"<ul> <li>Runs with <code>privileged: true</code> and <code>pid: host</code></li> <li>Monitors port 5000 for HTTP traffic</li> <li>Sends traces to OTel Collector</li> </ul>"},{"location":"ebpf/#when-to-use-ebpf-vs-sdk","title":"When to Use eBPF vs SDK","text":"<p>Use eBPF when:</p> <ul> <li>You can't modify application code (legacy apps, third-party binaries)</li> <li>You want basic HTTP observability with zero effort</li> <li>You're instrumenting many polyglot services quickly</li> </ul> <p>Use SDK when:</p> <ul> <li>You need rich application-level context in traces</li> <li>You need log-trace correlation</li> <li>You need custom spans for business logic</li> <li>You need full distributed tracing with context propagation</li> </ul> <p>Hybrid approach (this demo):</p> <ul> <li>Use eBPF for traces (zero-code)</li> <li>Use SDK for metrics and logs (richer data)</li> </ul>"},{"location":"ebpf/#configuration","title":"Configuration","text":""},{"location":"ebpf/#docker_1","title":"Docker","text":"<p>The eBPF agent is configured via environment variables in <code>docker-compose.yml</code>:</p> <pre><code>otel-ebpf-agent:\n  image: docker.io/otel/ebpf-instrument:main\n  privileged: true\n  pid: host\n  environment:\n    - OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317\n    - OTEL_EBPF_OPEN_PORT=5000\n  volumes:\n    - /sys/kernel/debug:/sys/kernel/debug:rw\n</code></pre>"},{"location":"ebpf/#kubernetes_1","title":"Kubernetes","text":""},{"location":"ebpf/#using-the-ollyscale-helm-chart-recommended","title":"Using the ollyScale Helm Chart (Recommended)","text":"<p>The easiest way to deploy the eBPF agent in Kubernetes is using the ollyScale Helm chart:</p> <pre><code># Install ollyScale with eBPF agent enabled\nhelm install ollyscale ./charts/ollyscale \\\n  --namespace ollyscale \\\n  --create-namespace \\\n  --set ebpfAgent.enabled=true \\\n  --set ebpfAgent.config.openPorts=\"5000,8080,3000\"\n</code></pre> <p>Or create a custom <code>values.yaml</code>:</p> <pre><code># values-with-ebpf.yaml\nebpfAgent:\n  enabled: true\n  config:\n    # Ports to instrument (comma-separated)\n    openPorts: \"5000,8080,3000\"\n    # Service name prefix\n    serviceName: \"my-app\"\n    # Collector endpoint\n    otlpEndpoint: \"http://gateway-collector.ollyscale.svc.cluster.local:4317\"\n  resources:\n    limits:\n      memory: 512Mi\n    requests:\n      cpu: 100m\n      memory: 256Mi\n</code></pre> <p>Then install:</p> <pre><code>helm install ollyscale ./charts/ollyscale \\\n  --namespace ollyscale \\\n  --create-namespace \\\n  --values values-with-ebpf.yaml\n</code></pre> <p>The Helm chart automatically creates:</p> <ul> <li>DaemonSet for eBPF agent (one pod per node)</li> <li>ServiceAccount with proper permissions</li> <li>ClusterRole/ClusterRoleBinding for node and pod access</li> <li>Integration with ollyScale's gateway collector</li> </ul>"},{"location":"ebpf/#manual-kubernetes-deployment","title":"Manual Kubernetes Deployment","text":"<p>In Kubernetes, the eBPF agent runs as a DaemonSet to instrument all pods on each node:</p> <pre><code>apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: otel-ebpf-agent\nspec:\n  template:\n    spec:\n      hostPID: true\n      containers:\n        - name: ebpf-agent\n          image: docker.io/otel/ebpf-instrument:main\n          securityContext:\n            privileged: true\n          env:\n            - name: OTEL_EXPORTER_OTLP_ENDPOINT\n              value: \"http://otel-collector:4317\"\n            - name: OTEL_EBPF_OPEN_PORT\n              value: \"5000\"\n          volumeMounts:\n            - name: sys-kernel-debug\n              mountPath: /sys/kernel/debug\n      volumes:\n        - name: sys-kernel-debug\n          hostPath:\n            path: /sys/kernel/debug\n</code></pre>"},{"location":"ebpf/#key-settings","title":"Key Settings","text":"<ul> <li><code>OTEL_EBPF_OPEN_PORT</code>: Which port to monitor (5000 = Flask default)</li> <li><code>privileged: true</code>: Required for eBPF kernel access</li> <li><code>hostPID: true</code> / <code>pid: host</code>: Required to see processes in other containers/pods</li> </ul>"},{"location":"ebpf/#troubleshooting","title":"Troubleshooting","text":"<p>No traces appearing?</p> <ul> <li>Ensure ollyScale core is running (<code>docker ps | grep otel-collector</code>)</li> <li>Check eBPF agent logs: <code>docker logs otel-ebpf-instrumentation</code></li> <li>Verify the agent can access <code>/sys/kernel/debug</code></li> </ul> <p>Traces have wrong service name?</p> <ul> <li>OBI discovers service names from process info</li> <li>Set <code>OTEL_EBPF_SERVICE_NAME</code> for explicit naming</li> </ul> <p>eBPF agent won't start?</p> <ul> <li>Requires Linux kernel 4.4+ with eBPF support</li> <li>On macOS, runs inside Docker's Linux VM (should work)</li> <li>Check Docker has sufficient privileges</li> </ul>"},{"location":"ebpf/#learn-more","title":"Learn More","text":"<ul> <li>OpenTelemetry eBPF Instrumentation Docs</li> <li>OBI GitHub Repository</li> <li>OBI Docker Setup Guide</li> </ul>"},{"location":"kubernetes/","title":"Kubernetes Deployment","text":"<p>Deploy ollyScale on Kubernetes (Minikube) for local development!</p> <p>Service map showing microservices running on Kubernetes</p> <p>All examples are launched from the repo - clone it first or download the current GitHub release archive:</p> <pre><code>git clone https://github.com/ryanfaircloth/ollyscale\n</code></pre>"},{"location":"kubernetes/#prerequisites","title":"Prerequisites","text":"<ul> <li>Minikube</li> <li>kubectl</li> </ul>"},{"location":"kubernetes/#1-deploy-ollyscale-core","title":"1. Deploy ollyScale Core","text":"<ol> <li> <p>Start Minikube:</p> <pre><code>minikube start\n</code></pre> </li> <li> <p>Deploy ollyScale:</p> <pre><code>Deploy using Helm (images will be pulled from Docker Hub automatically):\n\n```bash\ncd charts\n./install.sh\n```\n\n!!! note \"Local Development Build (Optional)\"\nTo build and deploy custom images for local development:\n`bash\n</code></pre> <p>cd charts ./build-and-push-local.sh  ` <li> <p>Access the UI:</p> <p>To access the ollyScale UI (Service Type: LoadBalancer) on macOS with Minikube, you need to use <code>minikube tunnel</code>.</p> <p>Open a new terminal window and run:</p> <pre><code>minikube tunnel\n</code></pre> <p>You may be asked for your password. Keep this terminal open.</p> <p>Now you can access the ollyScale UI at: http://localhost:5002</p> <p>OpenTelemetry Collector + OpAMP Config Page: Navigate to the \"OpenTelemetry Collector + OpAMP Config\" tab in the UI to view and manage collector configurations remotely. See the OpAMP Configuration section below for setup instructions.</p> </li> <li> <p>Send Telemetry from Host Apps:</p> <p>To send telemetry from applications running on your host machine (outside Kubernetes), use <code>kubectl port-forward</code> to expose the OTel Collector ports:</p> <p>Open a new terminal window and run:</p> <pre><code>kubectl port-forward service/otel-collector 4317:4317 4318:4318\n</code></pre> <p>Keep this terminal open. Now point your application's OpenTelemetry exporter to: - gRPC: <code>http://localhost:4317</code> - HTTP: <code>http://localhost:4318</code></p> <p>Example environment variables:</p> <pre><code>export OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318\n</code></pre> <p>For apps running inside the Kubernetes cluster: Use the Kubernetes service name: - gRPC: <code>http://otel-collector:4317</code> - HTTP: <code>http://otel-collector:4318</code></p> </li> <li> <p>Clean Up:</p> <p>Uninstall ollyScale using Helm:</p> <pre><code>helm uninstall ollyscale -n ollyscale\nkubectl delete namespace ollyscale\n</code></pre> <p>Shut down Minikube:</p> <pre><code>minikube stop\n</code></pre> <p>Minikube may be more stable if you delete it:</p> <pre><code>minikube delete\n</code></pre> </li>"},{"location":"kubernetes/#2-demo-applications-optional","title":"2. Demo Applications (Optional)","text":"<p>To see ollyScale in action with instrumented microservices:</p> <pre><code>cd k8s-demo\n./02-deploy.sh\n</code></pre> <p>The deploy script pulls demo images from Docker Hub by default. For local development, you can build images locally when prompted.</p> <p>To clean up the demo:</p> <pre><code>./03-cleanup.sh\n</code></pre> <p>The demo includes two microservices that automatically generate traffic, showcasing distributed tracing across service boundaries.</p>"},{"location":"kubernetes/#3-opentelemetry-demo-20-services-optional","title":"3. OpenTelemetry Demo (~20 Services - Optional)","text":"<p>To deploy the full OpenTelemetry Demo with ~20 microservices:</p> <p>Prerequisites:</p> <ul> <li>ollyScale must be deployed first (see Setup above)</li> <li>Helm installed</li> <li>Sufficient cluster resources (demo is resource-intensive)</li> </ul> <p>Deploy:</p> <pre><code>cd k8s-otel-demo\n./01-deploy-otel-demo-helm.sh\n</code></pre> <p>This deploys all OpenTelemetry Demo services configured to send telemetry to ollyScale's collector via HTTP on port 4318. Built-in observability tools (Jaeger, Grafana, Prometheus) are disabled.</p> <p>Cleanup:</p> <pre><code>cd k8s-otel-demo\n./02-cleanup-otel-demo-helm.sh\n</code></pre> <p>This removes the OpenTelemetry Demo but leaves ollyScale running.</p>"},{"location":"kubernetes/#4-ollyscale-core-only-deployment-use-your-own-kubernetes-opentelemetry-collector","title":"4. ollyScale Core-Only Deployment: Use Your Own Kubernetes OpenTelemetry Collector","text":"<p>To deploy ollyScale without the bundled OTel Collector (e.g., if you have an existing collector daemonset). Includes OpAMP server for optional remote collector configuration management:</p> <ol> <li>Deploy Core:</li> </ol> <pre><code>cd k8s-core-only\n./01-deploy.sh\n</code></pre> <ol> <li> <p>Access UI:    Run <code>minikube tunnel</code> and access <code>http://localhost:5002</code>.</p> </li> <li> <p>Cleanup:</p> </li> </ol> <pre><code>./02-cleanup.sh\n</code></pre>"},{"location":"kubernetes/#use-ollyscale-with-any-opentelemetry-collector","title":"Use ollyScale with Any OpenTelemetry Collector","text":"<p>Swap out the included Otel Collector for any distro of Otel Collector.</p> <p>Point your OpenTelemetry exporters to ollyscale-otlp-receiver:4343: i.e.</p> <pre><code>exporters:\n  debug:\n    verbosity: detailed\n\n  otlp:\n    endpoint: \"ollyscale-otlp-receiver:4343\"\n    tls:\n      insecure: true\n\nservice:\n  pipelines:\n    traces:\n      receivers: [otlp]\n      processors: [batch]\n      exporters: [debug, otlp, spanmetrics]\n\n    metrics:\n      receivers: [otlp, spanmetrics]\n      processors: [batch]\n      exporters: [debug, otlp]\n\n    logs:\n      receivers: [otlp]\n      processors: [batch]\n      exporters: [debug, otlp]\n</code></pre> <p>The Otel Collector will forward everything to ollyScale's OTLP receiver, which process telemetry and stores it in Redis in OTEL format for the backend and UI to access.</p>"},{"location":"kubernetes/#opamp-configuration-optional","title":"OpAMP Configuration (Optional)","text":"<p>The OpenTelemetry Collector + OpAMP Config page in the ollyScale UI allows you to view and manage collector configurations remotely. To enable this feature, add the OpAMP extension to your collector config:</p> <pre><code>extensions:\n  opamp:\n    server:\n      ws:\n        endpoint: ws://ollyscale-opamp-server:4320/v1/opamp\n\nservice:\n  extensions: [opamp]\n</code></pre> <p>The default configuration template (included as a ConfigMap in <code>k8s-core-only/ollyscale-opamp-server.yaml</code>) shows a complete example with OTLP receivers, OpAMP extension, batch processing, and spanmetrics connector. Your collector will connect to the OpAMP server and receive configuration updates through the ollyScale UI.</p>"},{"location":"kubernetes/#building-images","title":"Building Images","text":"<p>By default, deployment scripts pull pre-built images from GitHub Container Registry (GHCR). For building images locally (Minikube) or publishing to GHCR, see build/README.md.</p>"},{"location":"licensing/","title":"Licensing","text":"<p>ollyScale is released under the BSD 3-Clause License. The full license text is available in the LICENSE file. This license permits free use, modification, and redistribution for individuals, researchers, and small organizations.</p> <p>This project is forked from the BSD 3-Clause license and maintained by Ryan Faircloth. Eventually I will update the logo and naming to avoid confusion with the original project.</p>"},{"location":"metrics/","title":"Metrics &amp; Cardinality explorer","text":"<p>ollyScale provides a powerful interface for analyzing OpenTelemetry metrics, with specific tools designed to help you understand the shape and cardinality of your telemetry data.</p>"},{"location":"metrics/#metrics-table","title":"Metrics Table","text":"<p>The metrics table offers a dense, high-information view of all ingested metrics.</p> <p></p> <p>Click the Chart button to visualize metric data over time:</p> <p></p>"},{"location":"metrics/#key-columns","title":"Key Columns","text":"<ul> <li>Name: The full OTel metric name (e.g., <code>http.server.response.size</code>).</li> <li>Unit: The unit of measurement (e.g., <code>By</code>, <code>ms</code>).</li> <li>Type: The metric type (Histogram, Sum, Gauge, etc.).</li> <li>Resources: Click to view the unique resource combinations associated with this metric.</li> <li>Cardinality: Shows the number of label dimensions vs the total number of unique time series (e.g., <code>8 labels / 185 series</code>).</li> </ul>"},{"location":"metrics/#cardinality-explorer","title":"Cardinality Explorer","text":"<p>Clicking on the blue Cardinality link for any metric opens the Cardinality Explorer. This tool is essential for understanding \"high cardinality\" issues and exploring your data's dimensions.</p>"},{"location":"metrics/#1-header-stats","title":"1. Header Stats","text":"<ul> <li>Total Series (Historic): The total number of unique time series seen for this metric since startup (persisted in Redis).</li> <li>Active Series (1h): The count of series seen in the last hour.</li> <li>Label Dimensions: The number of unique label keys (e.g., <code>http.method</code>, <code>http.status_code</code>).</li> </ul>"},{"location":"metrics/#2-label-analysis-table","title":"2. Label Analysis Table","text":"<p>This table helps you identify which labels are contributing most to your cardinality.</p> <ul> <li>Label Name: The key of the label.</li> <li>Cardinality: The number of unique values for this label.</li> <li>Values (Top 5): A preview of the most common values.</li> <li>If there are more than 5 values, a clickable <code>...</code> link expands the list to show all values inline.</li> </ul>"},{"location":"metrics/#3-raw-active-series","title":"3. Raw Active Series","text":"<p>A scrollable view of all active series in a PromQL-like syntax:</p> <pre><code>{container.id=\"...\", http.method=\"GET\", http.route=\"/api/traces\", http.status_code=\"200\", service.name=\"ollyscale-ui\"}\n{container.id=\"...\", http.method=\"GET\", http.route=\"/health\", http.status_code=\"200\", service.name=\"ollyscale-ui\"}\n</code></pre>"},{"location":"metrics/#export-actions","title":"Export Actions","text":"<p>Use the buttons in the \"Raw Active Series\" section to export data for offline analysis:</p> <ul> <li>Copy PromQL: Copies the visible series list to your clipboard.</li> <li>Download JSON: Downloads the full series object as a JSON file.</li> </ul>"},{"location":"metrics/#cardinality-protection","title":"Cardinality Protection","text":"<p>ollyScale includes built-in protection against cardinality explosions to prevent memory exhaustion during local development.</p> <ul> <li>Hard Limit: 1000 unique metric names (configurable).</li> <li>Visual Warnings:</li> <li>\u26a0\ufe0f Yellow: &gt; 70% capacity</li> <li>\ud83d\udd34 Red: &gt; 90% capacity</li> <li>Behavior: Metrics exceeding the limit are dropped, and a system alert is triggered.</li> </ul> <p>See Cardinality Protection for more details.</p>"},{"location":"otel-collector/","title":"OpenTelemetry Collector","text":"<p>OpenTelemetry Collector configuration management via OpAMP</p> <p>ollyScale uses the OpenTelemetry Collector as the telemetry ingestion and shipping layer. The collector receives telemetry from your applications and forwards it to ollyScale's OTLP receiver.</p>"},{"location":"otel-collector/#opentelemetry-collector-opamp-config-page","title":"OpenTelemetry Collector + OpAMP Config Page","text":"<p>ollyScale includes a web interface for managing OpenTelemetry Collector configurations via the OpAMP (Open Agent Management Protocol). Access this page through the \"OpenTelemetry Collector + OpAMP Config\" tab in the ollyScale UI.</p> <p>Features:</p> <ul> <li>View current configuration from connected collectors</li> <li>Apply configuration changes with real-time validation</li> <li>Browse configuration templates for common use cases</li> <li>Monitor OpAMP server status and connected agents</li> <li>Preview configuration diffs before applying</li> </ul> <p>Requirements:</p> <ul> <li>Your collector must be configured with the OpAMP extension (see OpAMP Configuration below)</li> <li>Collector must be connected to the OpAMP server</li> </ul>"},{"location":"otel-collector/#configuration","title":"Configuration","text":"<p>ollyScale includes a sample collector configuration that you can customize for your needs. The configuration files are located at:</p> <ul> <li>Docker: <code>docker/otelcol-configs/config.yaml</code></li> <li>Kubernetes (Helm): Configured via Helm values - see <code>charts/ollyscale/values.yaml</code> for OTel Collector settings</li> </ul>"},{"location":"otel-collector/#default-configuration","title":"Default Configuration","text":"<p>The default configuration includes:</p> <ul> <li>OTLP Receivers: Accepts telemetry on ports 4317 (gRPC) and 4318 (HTTP)</li> <li>OpAMP Extension: Enables remote configuration management via ollyScale UI</li> <li>Span Metrics Connector: Automatically generates RED metrics from traces</li> <li>Batch Processor: Batches telemetry for efficient processing</li> <li>OTLP Exporter: Forwards all telemetry to ollyScale's OTLP receiver</li> </ul>"},{"location":"otel-collector/#customization-examples","title":"Customization Examples","text":"<p>You can extend the collector configuration to add additional capabilities. The collector uses the <code>otel/opentelemetry-collector-contrib</code> image which includes:</p> <ul> <li>Receivers: OTLP, Prometheus, Jaeger, Zipkin, and many more</li> <li>Processors: Batch, Memory Limiter, Resource Detection, Tail Sampling, Filtering</li> <li>Connectors: Span Metrics, Service Graph</li> <li>Exporters: OTLP, Prometheus, Logging, and many more</li> </ul> <p>For a complete list of available components, see the OpenTelemetry Collector Contrib documentation.</p>"},{"location":"otel-collector/#applying-changes","title":"Applying Changes","text":""},{"location":"otel-collector/#docker","title":"Docker","text":"<p>After modifying <code>docker/otelcol-configs/config.yaml</code> rebuild/restart using:</p> <pre><code>cd docker\n./01-start-core.sh\n</code></pre>"},{"location":"otel-collector/#kubernetes","title":"Kubernetes","text":"<p>When deployed via Helm, the OTel Collector is managed by the OpenTelemetry Operator. To customize the configuration:</p> <ol> <li>Edit <code>charts/ollyscale/values.yaml</code> under the <code>otelCollector</code> section</li> <li>Apply changes:</li> </ol> <pre><code>cd charts\nhelm upgrade ollyscale ./ollyscale -n ollyscale\n</code></pre> <p>Alternatively, patch the OpenTelemetryCollector custom resource directly:</p> <pre><code>kubectl edit opentelemetrycollector ollyscale-otel-collector -n ollyscale\n</code></pre>"},{"location":"otel-collector/#using-your-own-collector","title":"Using Your Own Collector","text":"<p>You can use your own OpenTelemetry Collector instance instead of the one bundled with ollyScale. This is useful if you have an existing collector setup or want to test specific collector configurations.</p> <p>To do this, deploy the Core-Only version of ollyScale (see Docker Deployment or Kubernetes Deployment).</p> <p>Then, configure your collector's OTLP exporter to send data to the ollyScale Receiver:</p> <ul> <li>Endpoint: <code>ollyscale-otlp-receiver:4343</code> (or <code>localhost:4343</code> from host)</li> <li>Protocol: gRPC</li> <li>TLS: Insecure (or configured as needed)</li> </ul> <p>Example Exporter Configuration:</p> <pre><code>exporters:\n  otlp:\n    endpoint: \"ollyscale-otlp-receiver:4343\"\n    tls:\n      insecure: true\n</code></pre>"},{"location":"otel-collector/#opamp-configuration-optional","title":"OpAMP Configuration (Optional)","text":"<p>The OpenTelemetry Collector + OpAMP Config page in the ollyScale UI allows you to view and manage collector configurations remotely. To enable this feature, add the OpAMP extension to your collector config:</p> <pre><code>extensions:\n  opamp:\n    server:\n      ws:\n        endpoint: ws://localhost:4320/v1/opamp\n\nservice:\n  extensions: [opamp]\n</code></pre> <p>The default configuration template (located at <code>docker/otelcol-configs/config.yaml</code>) shows a complete example with OTLP receivers, OpAMP extension, batch processing, and spanmetrics connector. Your collector will connect to the OpAMP server and receive configuration updates through the ollyScale UI.</p>"},{"location":"precommit/","title":"Pre-commit Configuration for ollyScale","text":"<p>This project uses pre-commit to maintain code quality and consistency across all languages and tools.</p>"},{"location":"precommit/#quick-start","title":"Quick Start","text":"<pre><code># Install and setup hooks\nmake precommit-setup\n\n# Or manually\npip install pre-commit\npre-commit install\n</code></pre>"},{"location":"precommit/#what-gets-checked","title":"What Gets Checked","text":""},{"location":"precommit/#python","title":"Python","text":"<ul> <li>ruff: Linting and formatting (replaces black, isort, flake8, pylint)</li> <li>Auto-fixes import sorting, formatting, and common issues</li> <li>Config: <code>pyproject.toml</code></li> </ul>"},{"location":"precommit/#yaml","title":"YAML","text":"<ul> <li>yamlfmt: Formatting and style consistency</li> <li>check-yaml: Syntax validation</li> <li>Config: <code>.yamlfmt</code></li> </ul>"},{"location":"precommit/#json","title":"JSON","text":"<ul> <li>prettier: Formatting</li> <li>check-json: Syntax validation</li> </ul>"},{"location":"precommit/#shell-scripts","title":"Shell Scripts","text":"<ul> <li>shellcheck: Linting for bash/sh scripts</li> <li>Catches common bugs and anti-patterns</li> </ul>"},{"location":"precommit/#docker","title":"Docker","text":"<ul> <li>hadolint: Dockerfile linting</li> <li>Enforces best practices (layer caching, security, maintainability)</li> <li>Config: <code>.hadolint.yaml</code></li> </ul>"},{"location":"precommit/#helm","title":"Helm","text":"<ul> <li>helmlint: Validates Helm chart structure and templates</li> <li>Runs on all charts in <code>charts/</code></li> </ul>"},{"location":"precommit/#go","title":"Go","text":"<ul> <li>golangci-lint: Comprehensive Go linting</li> <li>Auto-fixes when possible</li> </ul>"},{"location":"precommit/#markdown","title":"Markdown","text":"<ul> <li>markdownlint: Style and syntax checking</li> <li>Config: <code>.markdownlint.yaml</code></li> </ul>"},{"location":"precommit/#terraform","title":"Terraform","text":"<ul> <li>terraform fmt: Format HCL files</li> <li>terraform validate: Validate configuration</li> </ul>"},{"location":"precommit/#general","title":"General","text":"<ul> <li>Trailing whitespace removal</li> <li>End-of-file fixer</li> <li>Large file detection (&gt;1MB)</li> <li>Private key detection</li> <li>Merge conflict detection</li> </ul>"},{"location":"precommit/#usage","title":"Usage","text":""},{"location":"precommit/#automatic-recommended","title":"Automatic (Recommended)","text":"<p>Hooks run automatically on <code>git commit</code>. If checks fail, the commit is blocked:</p> <pre><code>git add .\ngit commit -m \"feat: add new feature\"\n# Pre-commit runs, auto-fixes issues, then commits\n</code></pre>"},{"location":"precommit/#manual","title":"Manual","text":"<pre><code># Run all checks\nmake lint\n# Or: pre-commit run --all-files\n\n# Run specific hook\npre-commit run ruff --all-files\npre-commit run hadolint-docker --all-files\n\n# Run on specific files\npre-commit run --files apps/ollyscale/main.py apps/demo/backend.py\n\n# Update hooks to latest versions\npre-commit autoupdate\n</code></pre>"},{"location":"precommit/#skip-hooks-not-recommended","title":"Skip Hooks (Not Recommended)","text":"<pre><code># Skip all hooks (emergency only)\ngit commit --no-verify -m \"hotfix\"\n\n# Skip specific files by adding to exclude in .pre-commit-config.yaml\n</code></pre>"},{"location":"precommit/#configuration-files","title":"Configuration Files","text":"<ul> <li><code>.pre-commit-config.yaml</code> - Main hook configuration</li> <li><code>pyproject.toml</code> - Python/ruff settings</li> <li><code>.hadolint.yaml</code> - Docker linting rules</li> <li><code>.markdownlint.yaml</code> - Markdown style rules</li> <li><code>.yamlfmt</code> - YAML formatting rules</li> </ul>"},{"location":"precommit/#troubleshooting","title":"Troubleshooting","text":""},{"location":"precommit/#hooks-fail-on-first-run","title":"Hooks fail on first run","text":"<p>This is normal. Pre-commit will auto-fix many issues. Run again:</p> <pre><code>git add .\ngit commit -m \"fix: apply pre-commit auto-fixes\"\n</code></pre>"},{"location":"precommit/#command-not-found-pre-commit","title":"\"command not found: pre-commit\"","text":"<pre><code>pip install pre-commit\npre-commit install\n</code></pre>"},{"location":"precommit/#hook-installation-fails","title":"Hook installation fails","text":"<pre><code># Clear cache and reinstall\npre-commit clean\npre-commit install --install-hooks\n</code></pre>"},{"location":"precommit/#specific-hook-keeps-failing","title":"Specific hook keeps failing","text":"<pre><code># Run in verbose mode for debugging\npre-commit run &lt;hook-id&gt; --all-files --verbose\n\n# Temporarily skip hook (not recommended)\nSKIP=&lt;hook-id&gt; git commit -m \"message\"\n</code></pre>"},{"location":"precommit/#adding-new-hooks","title":"Adding New Hooks","text":"<ol> <li>Find the hook at pre-commit.com hooks</li> <li>Add to <code>.pre-commit-config.yaml</code>:</li> </ol> <pre><code>- repo: https://github.com/org/repo\n  rev: v1.0.0\n  hooks:\n    - id: hook-name\n      args: [--option]\n</code></pre> <ol> <li>Install: <code>pre-commit install --install-hooks</code></li> <li>Test: <code>pre-commit run hook-name --all-files</code></li> </ol>"},{"location":"precommit/#ci-integration","title":"CI Integration","text":"<p>Pre-commit checks run in GitHub Actions workflows. See <code>.github/workflows/</code>.</p>"},{"location":"precommit/#performance","title":"Performance","text":"<ul> <li>First run: Slower (downloads and caches tools)</li> <li>Subsequent runs: Fast (only changed files)</li> <li>Full run: <code>pre-commit run --all-files</code> takes ~2-5 minutes</li> </ul>"},{"location":"precommit/#best-practices","title":"Best Practices","text":"<ol> <li>Run before pushing: <code>make lint</code> or <code>pre-commit run --all-files</code></li> <li>Commit auto-fixes separately: Let pre-commit fix, then review changes</li> <li>Keep hooks updated: <code>pre-commit autoupdate</code> monthly</li> <li>Don't skip hooks: They catch real issues before code review</li> <li>Fix root causes: If a hook fails repeatedly, fix the underlying issue</li> </ol>"},{"location":"precommit/#ruff-configuration-highlights","title":"Ruff Configuration Highlights","text":"<ul> <li>Target: Python 3.11+</li> <li>Line length: 120 characters</li> <li>Enabled checks:</li> <li>Code quality (pyflakes, pycodestyle)</li> <li>Import sorting (isort)</li> <li>Security (bandit subset)</li> <li>Complexity (pylint subset)</li> <li>Modern Python (pyupgrade)</li> <li>Auto-fix: Most issues fixed automatically</li> <li>Config: <code>pyproject.toml</code></li> </ul>"},{"location":"precommit/#docker-linting-highlights","title":"Docker Linting Highlights","text":"<ul> <li>Ignored rules:</li> <li>DL3008: Pin apt versions (handled by base images)</li> <li>DL3013: Pin pip versions (requirements.txt handles this)</li> <li>Trusted registries: docker.io, ghcr.io, gcr.io, registry.k8s.io</li> <li>Config: <code>.hadolint.yaml</code></li> </ul>"},{"location":"precommit/#support","title":"Support","text":"<ul> <li>Pre-commit docs: https://pre-commit.com</li> <li>Ruff docs: https://docs.astral.sh/ruff</li> <li>Hadolint docs: https://github.com/hadolint/hadolint</li> <li>Project issues: https://github.com/ryanfaircloth/ollyscale/issues</li> </ul>"},{"location":"quickstart/","title":"Quick Start","text":"<p>Get ollyScale running in under 5 minutes!</p>"},{"location":"quickstart/#what-youll-get","title":"What You'll Get","text":"<ul> <li>ollyScale UI at <code>http://localhost:5005</code></li> <li>OpenTelemetry Collector listening on ports 4317 (gRPC) and 4318 (HTTP)</li> <li>OpAMP Server for remote collector configuration management</li> <li>Demo microservices generating automatic telemetry</li> </ul>"},{"location":"quickstart/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker Desktop installed and running</li> <li>Git (to clone the repository)</li> <li>5 minutes of your time</li> </ul>"},{"location":"quickstart/#step-1-clone-the-repository","title":"Step 1: Clone the Repository","text":"<pre><code>git clone https://github.com/ryanfaircloth/ollyscale\ncd ollyscale\n</code></pre>"},{"location":"quickstart/#step-2-start-ollyscale-core","title":"Step 2: Start ollyScale Core","text":"<pre><code>cd docker\n./01-start-core.sh\n</code></pre> <p>This pulls pre-built images from Docker Hub and starts:</p> <ul> <li>OpenTelemetry Collector (ports 4317/4318)</li> <li>OpAMP Server (ports 4320/4321)</li> <li>ollyScale OTLP Receiver (internal)</li> <li>ollyScale UI (port 5005)</li> <li>Redis storage (internal)</li> </ul> <p>Deployment time: ~30 seconds (pulls from Docker Hub)</p> <p>For local development: Use <code>./01-start-core-local.sh</code> to build images locally.</p>"},{"location":"quickstart/#step-3-deploy-demo-apps-optional-but-recommended","title":"Step 3: Deploy Demo Apps (Optional but Recommended)","text":"<p>In a new terminal:</p> <pre><code>cd apps/demo\n./01-deploy-demo.sh\n</code></pre> <p>This pulls demo images from Docker Hub and deploys two Flask microservices that automatically generate traffic.</p> <p>Wait 30 seconds for telemetry to appear!</p> <p>For local development: Use <code>./01-deploy-demo-local.sh</code> to build images locally.</p>"},{"location":"quickstart/#step-4-open-the-ui","title":"Step 4: Open the UI","text":"<p>Open your browser to: <code>http://localhost:5005</code></p> <p>You should see:</p> <p>Trace waterfall with correlated logs and span timing</p>"},{"location":"quickstart/#step-5-explore-the-features","title":"Step 5: Explore the Features","text":""},{"location":"quickstart/#traces-tab","title":"Traces Tab","text":"<p>View distributed traces across microservices with timing waterfall.</p> <p>Span waterfall showing request timing breakdown with correlated logs</p> <p>Click on a span to view detailed JSON data:</p> <p>Span detail view with full OpenTelemetry attributes</p>"},{"location":"quickstart/#logs-tab","title":"Logs Tab","text":"<p>Browse logs with trace/span correlation. Filter by severity (Error, Warn, Info, Debug).</p> <p>Real-time logs with trace and span correlation</p> <p>Click on a log entry to view full details:</p> <p>Log detail view with full attributes and resource info</p> <p>Filter to show only errors:</p> <p>Filtered error logs with trace correlation</p>"},{"location":"quickstart/#metrics-tab","title":"Metrics Tab","text":"<p>Visualize metrics with automatic charting.</p> <p>Time-series metrics visualization with rate charts</p>"},{"location":"quickstart/#service-catalog","title":"Service Catalog","text":"<p>View all services with RED metrics (Rate, Errors, Duration).</p> <p>Service catalog with RED metrics for all services</p>"},{"location":"quickstart/#service-map","title":"Service Map","text":"<p>Visualize service dependencies with an interactive graph.</p> <p>Interactive service dependency map with latency information</p>"},{"location":"quickstart/#opentelemetry-collector-opamp-config","title":"OpenTelemetry Collector + OpAMP Config","text":"<p>View and manage your OpenTelemetry Collector configuration remotely via the OpAMP protocol.</p> <p>OpenTelemetry Collector configuration management via OpAMP</p> <p>This page allows you to:</p> <ul> <li>View current configuration from connected collectors</li> <li>Apply configuration changes with validation and diff preview</li> <li>Use configuration templates for common scenarios (default, prometheus-remote-write, etc.)</li> <li>Check OpAMP server status and see connected collector agents</li> <li>Validate configurations before applying to catch errors early</li> </ul> <p>To use this feature, your OpenTelemetry Collector must be configured with the OpAMP extension (see Docker Deployment or OpenTelemetry Collector documentation).</p>"},{"location":"quickstart/#step-6-use-your-own-application","title":"Step 6: Use Your Own Application","text":"<p>Point your application's OpenTelemetry exporter to:</p> <p>For apps running on your host machine (outside Docker):</p> <pre><code>export OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318\n</code></pre> <p>For apps running inside Docker:</p> <pre><code>export OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4318\n</code></pre> <p>ollyScale will automatically capture and display your telemetry!</p>"},{"location":"quickstart/#cleanup","title":"Cleanup","text":"<p>Stop demo apps (keeps ollyScale running):</p> <pre><code>cd apps/demo\n./02-cleanup-demo.sh\n</code></pre> <p>Stop everything:</p> <pre><code>cd docker\n./02-stop-core.sh\n</code></pre>"},{"location":"quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Configure your own OpenTelemetry Collector</li> <li>Explore the REST API at <code>http://localhost:5005/docs</code></li> <li>Deploy on Kubernetes</li> <li>Learn about the architecture</li> </ul>"},{"location":"quickstart/#troubleshooting","title":"Troubleshooting","text":""},{"location":"quickstart/#ui-shows-no-traceslogsmetrics","title":"UI shows \"No traces/logs/metrics\"","text":"<ul> <li>Wait 30 seconds after starting demo apps</li> <li>Check containers are running: <code>docker ps</code></li> <li>Check demo app logs: <code>docker compose -f apps/demo/docker-compose-demo.yml logs</code></li> </ul>"},{"location":"quickstart/#port-conflicts","title":"Port conflicts","text":"<ul> <li>ollyScale uses ports 4317, 4318, 4320, 4321, 4343, 5005, 6379, 19291</li> <li>Stop conflicting services or modify ports in <code>docker-compose-ollyscale-core.yml</code></li> </ul>"},{"location":"quickstart/#demo-apps-not-generating-traffic","title":"Demo apps not generating traffic","text":"<ul> <li>Restart demo: <code>cd apps/demo &amp;&amp; ./02-cleanup-demo.sh &amp;&amp; ./01-deploy-demo.sh</code></li> <li>Check logs: <code>docker compose -f apps/demo/docker-compose-demo.yml logs demo-frontend</code></li> </ul> <p>For more help, open an issue on GitHub.</p>"},{"location":"release-migration/","title":"Migration from semantic-release to release-please","text":"<p>This document explains the migration from semantic-release to release-please and what changed.</p>"},{"location":"release-migration/#why-migrate","title":"Why Migrate?","text":"<p>The previous semantic-release system had challenges with:</p> <ul> <li>Complex multi-package coordination requiring custom plugins</li> <li>All components released together even when only one changed</li> <li>Difficulty managing cross-component dependencies</li> <li>Complex configuration spread across multiple <code>.releaserc.json</code> files</li> </ul> <p>The new release-please system provides:</p> <ul> <li>Native multi-package support - no special plugins needed</li> <li>Separate releases - each component releases independently</li> <li>bumpDependents feature - automatic version bumping when dependencies change</li> <li>Simpler configuration - single <code>release-please-config.json</code> file</li> <li>Better visibility - separate PRs for each component release</li> </ul>"},{"location":"release-migration/#what-changed","title":"What Changed","text":""},{"location":"release-migration/#configuration-files","title":"Configuration Files","text":"<p>Removed:</p> <ul> <li>Individual <code>.releaserc.json</code> files in <code>apps/*/</code> and <code>charts/*/</code> \u2705 COMPLETED</li> <li>Root <code>.releaserc.json</code> \u2705 COMPLETED</li> <li><code>.multi-releaserc.json</code> \u2705 COMPLETED</li> <li>All semantic-release dependencies from <code>package.json</code> \u2705 COMPLETED</li> <li><code>.github/workflows/semantic-release.yml</code> \u2705 COMPLETED</li> </ul> <p>Added:</p> <ul> <li><code>release-please-config.json</code> - Main configuration for all components</li> <li><code>.release-please-manifest.json</code> - Version tracking manifest</li> </ul>"},{"location":"release-migration/#github-workflows","title":"GitHub Workflows","text":"<p>Removed:</p> <ul> <li><code>.github/workflows/semantic-release.yml</code> - Completely removed \u2705 COMPLETED</li> </ul> <p>Added:</p> <ul> <li><code>.github/workflows/release-please.yml</code> - New release workflow supporting multiple branches</li> </ul>"},{"location":"release-migration/#version-management","title":"Version Management","text":"<p>Before (semantic-release):</p> <pre><code># All components released together when main is updated\ngit push origin main\n# semantic-release runs and releases everything with changes\n</code></pre> <p>After (release-please):</p> <pre><code># Commit with conventional commit format\ngit commit -m \"feat(ollyscale): add new API endpoint\"\ngit push origin main\n\n# release-please creates/updates PR for ollyscale component\n# Merge the PR to trigger the release\n</code></pre>"},{"location":"release-migration/#dependency-management","title":"Dependency Management","text":"<p>Before (semantic-release):</p> <ul> <li>Each component's <code>.releaserc.json</code> had <code>semantic-release-yaml</code> plugin</li> <li>Manually specified which values.yaml fields to update</li> <li>No automatic chart version bumping</li> </ul> <p>After (release-please):</p> <ul> <li>App components update their image tags in values.yaml via <code>extra-files</code></li> <li>Chart has <code>bumpDependents: true</code> entries that watch for these changes</li> <li>Chart version automatically bumps when any dependency changes</li> </ul>"},{"location":"release-migration/#migration-steps","title":"Migration Steps","text":""},{"location":"release-migration/#for-developers","title":"For Developers","text":"<ol> <li>Commit message format stays the same - Continue using Conventional Commits</li> <li>Review release PRs - release-please creates PRs that need to be reviewed and merged</li> <li>Watch for dependency bumps - Chart releases may happen automatically due to bumpDependents</li> </ol>"},{"location":"release-migration/#for-maintainers","title":"For Maintainers","text":"<ol> <li>Bootstrap versions - Initial versions set in <code>.release-please-manifest.json</code></li> <li>Monitor first releases - Verify the workflow works correctly</li> <li>Update documentation - Point to new release system docs</li> <li>Remove old configs - After successful migration, remove semantic-release configs</li> </ol>"},{"location":"release-migration/#configuration-details","title":"Configuration Details","text":""},{"location":"release-migration/#component-configuration","title":"Component Configuration","text":"<p>Each component in <code>release-please-config.json</code> has:</p> <pre><code>{\n  \"apps/ollyscale\": {\n    \"component\": \"ollyscale\",           // Tag prefix: ollyscale-v1.0.0\n    \"release-type\": \"python\",           // Handles Python version files\n    \"package-name\": \"@ollyscale/ollyscale\",\n    \"extra-files\": [                    // Additional files to update\n      {\n        \"type\": \"yaml\",\n        \"path\": \"charts/ollyscale/values.yaml\",\n        \"jsonpath\": \"$.frontend.image.tag\"\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"release-migration/#dependency-management_1","title":"Dependency Management","text":"<p>The chart configuration uses <code>bumpDependents</code>:</p> <pre><code>{\n  \"charts/ollyscale\": {\n    \"component\": \"chart-ollyscale\",\n    \"release-type\": \"helm\",\n    \"extra-files\": [\n      {\n        \"type\": \"yaml\",\n        \"path\": \"charts/ollyscale/values.yaml\",\n        \"jsonpath\": \"$.frontend.image.tag\",\n        \"component\": \"ollyscale\",       // Watch this component\n        \"bumpDependents\": true          // Bump chart when ollyscale changes\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"release-migration/#release-flow-comparison","title":"Release Flow Comparison","text":""},{"location":"release-migration/#semantic-release-flow","title":"semantic-release Flow","text":"<pre><code>1. Push to main\n2. semantic-release runs for all workspaces\n3. Each workspace checks for changes\n4. Versions bumped, CHANGELOGs updated\n5. Docker images built and pushed\n6. Git tags created\n7. GitHub releases created\n</code></pre> <p>Issues:</p> <ul> <li>All workspaces processed even if unchanged</li> <li>Single workflow must handle all build types</li> <li>Complex plugin configuration per workspace</li> <li>No dependency tracking between components</li> </ul>"},{"location":"release-migration/#release-please-flow","title":"release-please Flow","text":"<pre><code>1. Push to main\n2. release-please creates/updates PR per component with changes\n3. Review and merge PR\n4. release-please creates release tag\n5. Workflow triggered by release tag\n6. Build and publish component (Docker/Helm)\n7. GitHub release created with notes\n</code></pre> <p>Benefits:</p> <ul> <li>Only changed components get PRs</li> <li>Review releases before they happen</li> <li>Matrix strategy handles builds cleanly</li> <li>bumpDependents tracks component relationships</li> </ul>"},{"location":"release-migration/#example-scenarios","title":"Example Scenarios","text":""},{"location":"release-migration/#scenario-1-app-change","title":"Scenario 1: App Change","text":"<pre><code># Make a change to ollyscale backend\ngit commit -m \"feat(ollyscale): add trace filtering\"\ngit push origin main\n\n# Results:\n# 1. release-please creates PR for apps/ollyscale\n# 2. PR updates version to 2.2.0 in package.json\n# 3. PR updates frontend.image.tag in values.yaml to v2.2.0\n# 4. bumpDependents detects this change\n# 5. release-please also creates PR for charts/ollyscale\n# 6. Chart version bumps to 0.2.0\n\n# Merge both PRs to release\n</code></pre>"},{"location":"release-migration/#scenario-2-chart-only-change","title":"Scenario 2: Chart-Only Change","text":"<pre><code># Update chart templates\ngit commit -m \"feat(chart-ollyscale): add podDisruptionBudget\"\ngit push origin main\n\n# Results:\n# 1. release-please creates PR for charts/ollyscale only\n# 2. Chart version bumps to 0.2.0\n# No app component changes needed\n</code></pre>"},{"location":"release-migration/#scenario-3-multiple-app-changes","title":"Scenario 3: Multiple App Changes","text":"<pre><code># Make changes to UI and backend\ngit commit -m \"feat(ollyscale-ui): improve timeline view\"\ngit commit -m \"fix(ollyscale): handle null span attributes\"\ngit push origin main\n\n# Results:\n# 1. release-please creates PR for apps/ollyscale-ui\n# 2. release-please creates PR for apps/ollyscale\n# 3. release-please creates PR for charts/ollyscale (due to bumpDependents)\n# All can be reviewed and merged independently\n</code></pre>"},{"location":"release-migration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"release-migration/#release-pr-not-created","title":"Release PR not created","text":"<p>Check:</p> <ol> <li>Commits follow Conventional Commit format</li> <li>Commits are in correct component directory</li> <li>Commits pushed to <code>main</code> branch</li> <li><code>.release-please-manifest.json</code> has entry for component</li> </ol>"},{"location":"release-migration/#chart-not-bumped-when-app-changes","title":"Chart not bumped when app changes","text":"<p>Check:</p> <ol> <li>App component has <code>extra-files</code> entry updating <code>values.yaml</code></li> <li>Chart has matching <code>bumpDependents: true</code> entry</li> <li>Component name matches exactly in both places</li> </ol>"},{"location":"release-migration/#build-fails-after-release","title":"Build fails after release","text":"<p>Check:</p> <ol> <li>Dockerfile exists and is valid</li> <li>GitHub token has packages:write permission</li> <li>Image name in workflow matches ghcr.io registry</li> </ol>"},{"location":"release-migration/#rollback-plan","title":"Rollback Plan","text":"<p>If the migration needs to be rolled back:</p> <ol> <li>Re-enable semantic-release workflow:</li> </ol> <pre><code># Remove \"if: false\" from .github/workflows/semantic-release.yml\n</code></pre> <ol> <li>Restore <code>.releaserc.json</code> files from git history:</li> </ol> <pre><code>git checkout &lt;previous-commit&gt; -- apps/*/.releaserc.json charts/*/.releaserc.json\n</code></pre> <ol> <li>Remove release-please configuration:</li> </ol> <pre><code>git rm release-please-config.json .release-please-manifest.json\ngit rm .github/workflows/release-please.yml\n</code></pre>"},{"location":"release-migration/#questions","title":"Questions?","text":"<p>See docs/release-system.md for complete documentation or open an issue on GitHub.</p>"},{"location":"release-process/","title":"ollyScale Release Process","text":"<p>ollyScale uses release-please for automated releases in our monorepo.</p>"},{"location":"release-process/#how-it-works","title":"How It Works","text":"<ol> <li>Make changes using Conventional Commits</li> <li>Merge to main - release-please creates/updates a release PR automatically</li> <li>Review release PR - check versions, changelogs, and changes</li> <li>Merge release PR - triggers automated builds and releases</li> </ol>"},{"location":"release-process/#conventional-commit-format","title":"Conventional Commit Format","text":"<pre><code>&lt;type&gt;(&lt;scope&gt;): &lt;description&gt;\n\n[optional body]\n\n[optional footer(s)]\n</code></pre>"},{"location":"release-process/#types-determine-version-bump","title":"Types (determine version bump)","text":"<ul> <li><code>feat:</code> - New feature (minor version bump)</li> <li><code>fix:</code> - Bug fix (patch version bump)</li> <li><code>perf:</code> - Performance improvement (patch version bump)</li> <li><code>docs:</code> - Documentation only (no release)</li> <li><code>style:</code> - Code style changes (no release)</li> <li><code>refactor:</code> - Code refactoring (patch version bump if in scope)</li> <li><code>test:</code> - Test changes (no release)</li> <li><code>build:</code> - Build system changes (no release)</li> <li><code>ci:</code> - CI configuration changes (no release)</li> <li><code>chore:</code> - Other changes (no release)</li> </ul> <p>Breaking Changes: Add <code>!</code> after type or <code>BREAKING CHANGE:</code> in footer for major version bump</p>"},{"location":"release-process/#scopes-optional-but-recommended","title":"Scopes (optional but recommended)","text":"<p>Container Components:</p> <ul> <li><code>ollyscale</code> - Core platform (apps/ollyscale)</li> <li><code>opamp</code> - OpAMP server (apps/opamp-server)</li> <li><code>demo</code> - Demo application (apps/demo)</li> <li><code>ai-agent</code> - AI agent demo (apps/ai-agent-demo)</li> </ul> <p>Helm Charts:</p> <ul> <li><code>helm/ollyscale</code> - Main platform chart</li> <li><code>helm/demos</code> - Demos chart</li> <li><code>helm/ai-agent</code> - AI agent chart</li> </ul> <p>General:</p> <ul> <li><code>deps</code> - Dependency updates</li> <li><code>*</code> - Multiple components (use sparingly)</li> </ul>"},{"location":"release-process/#examples","title":"Examples","text":""},{"location":"release-process/#container-changes","title":"Container Changes","text":"<pre><code># New feature in ollyscale (minor bump: 2.2.2 \u2192 2.3.0)\nfeat(ollyscale): add GenAI span filtering\n\n# Bug fix in opamp-server (patch bump: 1.0.0 \u2192 1.0.1)\nfix(opamp): handle nil pointer in config validation\n\n# Performance improvement (patch bump)\nperf(demo): optimize database query for metrics\n\n# Breaking change (major bump: 0.3.0 \u2192 1.0.0)\nfeat(ai-agent)!: migrate to Ollama 2.0 API\n\nBREAKING CHANGE: Ollama 1.x no longer supported\n</code></pre>"},{"location":"release-process/#helm-chart-changes","title":"Helm Chart Changes","text":"<pre><code># New chart feature (minor bump)\nfeat(helm/ollyscale): add PVC for persistent storage\n\n# Chart bug fix (patch bump)\nfix(helm/demos): correct service port configuration\n\n# Chart breaking change (major bump)\nfeat(helm/ollyscale)!: require Kubernetes 1.28+\n\nBREAKING CHANGE: Dropped support for Kubernetes &lt; 1.28\n</code></pre>"},{"location":"release-process/#multi-component-changes","title":"Multi-Component Changes","text":"<pre><code># Affects both containers and triggers chart update\nfeat(ollyscale,opamp): add mutual TLS authentication\n\n# Multiple charts\ndocs(helm/ollyscale,helm/demos): update README with examples\n</code></pre>"},{"location":"release-process/#no-release-examples","title":"No Release Examples","text":"<pre><code># Documentation only\ndocs: update API documentation\n\n# CI changes\nci: add workflow for dependency updates\n\n# Test changes\ntest(ollyscale): add integration tests for filtering\n\n# Build changes\nbuild: update base Python image to 3.12\n</code></pre>"},{"location":"release-process/#release-pr-workflow","title":"Release PR Workflow","text":""},{"location":"release-process/#when-changes-are-pushed-to-main","title":"When Changes Are Pushed to Main","text":"<ol> <li>Release-please analyzes commits since last release</li> <li>Determines which components need version bumps</li> <li>Creates/updates a single release PR with:</li> <li>Updated <code>.release-please-manifest.json</code> (single source of truth)</li> <li>Updated CHANGELOG.md for each component</li> <li>Updated Chart.yaml versions for Helm charts</li> <li>All changes in one PR</li> </ol>"},{"location":"release-process/#example-release-pr","title":"Example Release PR","text":"<pre><code>Title: chore: release main\n\nComponents to be released:\n- ollyscale: 2.2.2 \u2192 2.3.0\n- opamp-server: 1.0.0 \u2192 1.0.1\n- helm-ollyscale: 0.1.1 \u2192 0.2.0\n\nChanges:\n- Updated apps/ollyscale/VERSION\n- Updated apps/ollyscale/CHANGELOG.md\n- Updated apps/opamp-server/VERSION\n- Updated apps/opamp-server/CHANGELOG.md\n- Updated charts/ollyscale/Chart.yaml\n- Updated charts/ollyscale/CHANGELOG.md\n</code></pre>"},{"location":"release-process/#when-release-pr-is-merged","title":"When Release PR Is Merged","text":"<ol> <li>GitHub releases created for each component with tags:</li> <li><code>ollyscale-v2.3.0</code></li> <li><code>opamp-server-v1.0.1</code></li> <li> <p><code>helm-ollyscale-v0.2.0</code></p> </li> <li> <p>Container images built and pushed:</p> </li> <li><code>ghcr.io/ollyscale/ollyscale:v2.3.0</code> (+ <code>:latest</code>)</li> <li> <p><code>ghcr.io/ollyscale/opamp-server:v1.0.1</code> (+ <code>:latest</code>)</p> </li> <li> <p>Helm charts packaged and pushed:</p> </li> <li><code>oci://ghcr.io/ollyscale/charts/ollyscale:0.2.0</code></li> <li>Chart's <code>values.yaml</code> updated with new image versions</li> </ol>"},{"location":"release-process/#version-strategy","title":"Version Strategy","text":""},{"location":"release-process/#container-images","title":"Container Images","text":"<p>Each container maintains independent semantic versioning:</p> <pre><code>ollyscale:         v2.3.0\nopamp-server:     v1.0.1\ndemo:             v0.5.2\nai-agent-demo:    v0.3.1\n</code></pre>"},{"location":"release-process/#helm-charts","title":"Helm Charts","text":"<p>Charts have two version fields:</p> <ul> <li><code>version</code>: Chart's semantic version (no 'v' prefix)</li> <li><code>appVersion</code>: Version of primary application</li> </ul> <p>Release triggers:</p> <ul> <li>Direct changes to chart files</li> <li>Dependency container version bumps</li> <li>Manual version bump in manifest</li> </ul>"},{"location":"release-process/#local-development","title":"Local Development","text":"<p>Local development builds bypass release-please:</p> <pre><code># Build for local KIND cluster (no version tracking)\ncd charts\n./build-and-push-local.sh v2.3.0-my-feature\n\n# Or use existing build scripts\ncd scripts/build\n./02-build-all.sh local-test\n</code></pre> <p>Local builds:</p> <ul> <li>Use custom version tags (e.g., <code>local-</code>, feature names)</li> <li>Push only to local registry</li> <li>Don't update manifest (versions managed by release-please only)</li> <li>Don't trigger releases</li> </ul>"},{"location":"release-process/#manual-version-bumps","title":"Manual Version Bumps","text":"<p>If you need to force a version bump without code changes:</p> <pre><code># Update manifest file\nvim .release-please-manifest.json\n\n# Change version for component:\n{\n  \"apps/ollyscale\": \"2.3.0\",  # Bump this\n  ...\n}\n\n# Commit with chore type (won't trigger another bump)\ngit add .release-please-manifest.json\ngit commit -m \"chore: bump ollyscale to v2.3.0\"\ngit push origin main\n</code></pre>"},{"location":"release-process/#coordinated-releases","title":"Coordinated Releases","text":""},{"location":"release-process/#scenario-both-ollyscale-and-opamp-server-updated","title":"Scenario: Both ollyscale and opamp-server updated","text":"<pre><code># Commit 1\nfeat(ollyscale): add TLS support\n\n# Commit 2\nfeat(opamp): add TLS configuration endpoint\n\n# Result: Single release PR with:\n# - ollyscale: 2.2.2 \u2192 2.3.0\n# - opamp-server: 1.0.0 \u2192 1.1.0\n# - helm-ollyscale: 0.1.1 \u2192 0.2.0 (dependency bump)\n</code></pre> <p>Release-please automatically:</p> <ul> <li>Bumps both containers</li> <li>Bumps helm chart once (not twice)</li> <li>Updates chart's values.yaml with both new image versions</li> </ul>"},{"location":"release-process/#troubleshooting","title":"Troubleshooting","text":""},{"location":"release-process/#release-pr-not-created","title":"Release PR not created","text":"<ul> <li>Check commit messages follow conventional commits</li> <li>Verify commits have releasable types (<code>feat</code>, <code>fix</code>, <code>perf</code>)</li> <li>Check <code>.release-please-manifest.json</code> has correct initial versions</li> </ul>"},{"location":"release-process/#wrong-version-bump","title":"Wrong version bump","text":"<ul> <li>Check commit type (<code>feat</code> = minor, <code>fix</code> = patch)</li> <li>Verify <code>BREAKING CHANGE</code> in footer for major bumps</li> <li>Look at release PR description for bump reasoning</li> </ul>"},{"location":"release-process/#container-not-building-after-release","title":"Container not building after release","text":"<ul> <li>Check workflow logs in Actions tab</li> <li>Verify Dockerfile exists and is correct</li> <li>Check GHCR permissions</li> </ul>"},{"location":"release-process/#helm-chart-has-wrong-image-versions","title":"Helm chart has wrong image versions","text":"<ul> <li>Check <code>.release-please-manifest.json</code> for correct versions</li> <li>Verify <code>values.yaml</code> structure matches workflow expectations</li> <li>Ensure workflow's <code>yq</code> commands reference manifest correctly</li> </ul>"},{"location":"release-process/#best-practices","title":"Best Practices","text":"<ol> <li>One logical change per commit - easier to review and revert</li> <li>Use descriptive scopes - helps track which components changed</li> <li>Write clear descriptions - these become CHANGELOG entries</li> <li>Test before merging to main - releases are automatic</li> <li>Review release PR carefully - check all versions and changelogs</li> <li>Keep breaking changes to majors - minimize disruption</li> </ol>"},{"location":"release-process/#tools","title":"Tools","text":""},{"location":"release-process/#commitlint-optional","title":"Commitlint (optional)","text":"<p>Enforce conventional commits with pre-commit hooks:</p> <pre><code>npm install -g @commitlint/cli @commitlint/config-conventional\necho \"module.exports = {extends: ['@commitlint/config-conventional']}\" &gt; commitlint.config.js\n\n# Add to .git/hooks/commit-msg or use husky\n</code></pre>"},{"location":"release-process/#commit-message-templates","title":"Commit Message Templates","text":"<pre><code># Set git template\ngit config commit.template .gitmessage\n\n# .gitmessage content:\n# &lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;\n#\n# &lt;body&gt;\n#\n# &lt;footer&gt;\n#\n# Types: feat, fix, docs, style, refactor, perf, test, build, ci, chore\n# Scopes: ollyscale, opamp, demo, ai-agent, helm/ollyscale, helm/demos, helm/ai-agent\n</code></pre>"},{"location":"release-process/#migration-from-current-process","title":"Migration from Current Process","text":"<ol> <li>\u2705 Release-please configured</li> <li>\u2705 VERSION files removed (manifest is single source of truth)</li> <li>\u2705 Manifest initialized with current versions</li> <li>\u2705 GitHub Actions workflow created</li> <li>\u2705 Team documentation updated</li> <li>\u2705 Conventional commits in use</li> <li>\u2705 Multiple successful releases completed</li> <li>\u2705 Old release workflow deprecated</li> </ol>"},{"location":"release-process/#references","title":"References","text":"<ul> <li>Release Please Documentation</li> <li>Conventional Commits Spec</li> <li>Semantic Versioning</li> <li>Keep a Changelog</li> </ul>"},{"location":"release-system/","title":"Release System Documentation","text":""},{"location":"release-system/#overview","title":"Overview","text":"<p>This project uses release-please with a custom fork that supports the <code>bumpDependents</code> feature for managing cross-component version dependencies.</p>"},{"location":"release-system/#architecture","title":"Architecture","text":""},{"location":"release-system/#components","title":"Components","text":"<p>The repository contains multiple components that are released independently:</p> <p>Applications (Container Images):</p> <ul> <li><code>apps/ollyscale</code> - Python backend \u2192 <code>ghcr.io/ryanfaircloth/ollyscale/ollyscale</code></li> <li><code>apps/ollyscale-ui</code> - TypeScript frontend \u2192 <code>ghcr.io/ryanfaircloth/ollyscale/ollyscale-ui</code></li> <li><code>apps/opamp-server</code> - Go OpAMP server \u2192 <code>ghcr.io/ryanfaircloth/ollyscale/opamp-server</code></li> <li><code>apps/demo</code> - Demo application \u2192 <code>ghcr.io/ryanfaircloth/ollyscale/demo</code></li> <li><code>apps/demo-otel-agent</code> - Demo OTel agent \u2192 <code>ghcr.io/ryanfaircloth/ollyscale/demo-otel-agent</code></li> </ul> <p>Helm Charts:</p> <ul> <li><code>charts/ollyscale</code> - Main application chart \u2192 <code>ghcr.io/ryanfaircloth/ollyscale/charts/ollyscale</code></li> <li><code>charts/ollyscale-demos</code> - Demo charts \u2192 <code>ghcr.io/ryanfaircloth/ollyscale/charts/ollyscale-demos</code></li> <li><code>charts/ollyscale-otel-agent</code> - OTel agent chart \u2192 <code>ghcr.io/ryanfaircloth/ollyscale/charts/ollyscale-otel-agent</code></li> </ul>"},{"location":"release-system/#dependency-management-with-bumpdependents","title":"Dependency Management with bumpDependents","text":"<p>The <code>bumpDependents</code> feature automatically bumps the Helm chart version when any of its application dependencies are released. This is configured in <code>release-please-config.json</code>:</p> <pre><code>{\n  \"charts/ollyscale\": {\n    \"extra-files\": [\n      {\n        \"type\": \"yaml\",\n        \"path\": \"charts/ollyscale/values.yaml\",\n        \"jsonpath\": \"$.frontend.image.tag\",\n        \"component\": \"ollyscale\",\n        \"bumpDependents\": true\n      }\n    ]\n  }\n}\n</code></pre> <p>When <code>apps/ollyscale</code> gets a new release:</p> <ol> <li>The app's version is bumped (e.g., <code>v2.1.9</code> \u2192 <code>v2.1.10</code>)</li> <li>The app updates <code>charts/ollyscale/values.yaml</code> with <code>frontend.image.tag: v2.1.10</code></li> <li>The chart detects this change via <code>bumpDependents: true</code></li> <li>The chart version is automatically bumped (e.g., <code>0.1.0</code> \u2192 <code>0.1.1</code>)</li> </ol>"},{"location":"release-system/#release-workflow","title":"Release Workflow","text":""},{"location":"release-system/#supported-branches","title":"Supported Branches","text":"<p>The release-please workflow triggers on pushes to these branches:</p> <ul> <li><code>main</code> - Stable releases (Docker images tagged with <code>latest</code>)</li> <li><code>develop</code> - Pre-release builds</li> <li><code>next-release</code> - Pre-release builds for minor version testing</li> <li><code>next-release-major</code> - Pre-release builds for major version testing</li> </ul> <p>Pre-release behavior:</p> <ul> <li>All branches except <code>main</code> produce pre-release builds</li> <li>Pre-release Docker images do NOT get the <code>latest</code> tag</li> <li>GitHub releases marked as pre-releases</li> <li>Images labeled with <code>org.opencontainers.image.prerelease=true</code></li> </ul>"},{"location":"release-system/#automatic-releases","title":"Automatic Releases","text":"<ol> <li>Commit with Conventional Commit messages to any supported branch:</li> <li><code>feat:</code> - triggers a minor version bump (0.x.0)</li> <li><code>fix:</code> - triggers a patch version bump (0.0.x)</li> <li> <p><code>feat!:</code> or <code>BREAKING CHANGE:</code> - triggers a major version bump (x.0.0)</p> </li> <li> <p>release-please creates/updates PRs for each component that has unreleased changes:</p> </li> <li>One PR per component (separate-pull-requests: true)</li> <li>Includes CHANGELOG updates</li> <li> <p>Updates version in package files</p> </li> <li> <p>Merge the release PR to trigger the release:</p> </li> <li>Builds and pushes Docker images (multi-platform: amd64/arm64)</li> <li>Packages and publishes Helm charts to OCI registry</li> <li>Creates GitHub releases with notes</li> </ol>"},{"location":"release-system/#manual-pre-releases","title":"Manual Pre-releases","text":"<p>For testing releases before production:</p> <pre><code># Trigger via GitHub UI or gh CLI on any branch\ngh workflow run release-please.yml -f prerelease=true\n</code></pre> <p>Pre-releases:</p> <ul> <li>Tagged as pre-release in GitHub</li> <li>Docker images do NOT get the <code>latest</code> tag</li> <li>Useful for testing in staging environments</li> </ul>"},{"location":"release-system/#configuration-files","title":"Configuration Files","text":""},{"location":"release-system/#release-please-configjson","title":"release-please-config.json","text":"<p>Main configuration file defining:</p> <ul> <li>Component locations (<code>packages</code>)</li> <li>Release types (python, node, helm, simple)</li> <li>Extra files to update (version files, image tags)</li> <li>Dependency relationships (<code>bumpDependents</code>)</li> </ul>"},{"location":"release-system/#release-please-manifestjson","title":".release-please-manifest.json","text":"<p>Tracks the current version of each component. This file is automatically updated by release-please when releases are created.</p> <pre><code>{\n  \"apps/ollyscale\": \"2.1.9\",\n  \"apps/ollyscale-ui\": \"0.0.0\",\n  \"charts/ollyscale\": \"0.1.0\"\n}\n</code></pre>"},{"location":"release-system/#conventional-commit-format","title":"Conventional Commit Format","text":"<p>Follow Conventional Commits specification:</p> <pre><code>&lt;type&gt;[optional scope]: &lt;description&gt;\n\n[optional body]\n\n[optional footer(s)]\n</code></pre> <p>Types:</p> <ul> <li><code>feat</code>: New feature (minor bump)</li> <li><code>fix</code>: Bug fix (patch bump)</li> <li><code>docs</code>: Documentation changes (no bump)</li> <li><code>chore</code>: Maintenance tasks (no bump)</li> <li><code>refactor</code>: Code refactoring (no bump)</li> <li><code>test</code>: Test updates (no bump)</li> <li><code>ci</code>: CI/CD changes (no bump)</li> </ul> <p>Scopes (optional):</p> <ul> <li>Component names: <code>ollyscale</code>, <code>ollyscale-ui</code>, <code>opamp-server</code>, <code>chart-ollyscale</code></li> <li>Functional areas: <code>api</code>, <code>ui</code>, <code>storage</code>, <code>ingestion</code></li> </ul> <p>Examples:</p> <pre><code># Feature in ollyscale backend\ngit commit -m \"feat(ollyscale): add span filtering API\"\n\n# Fix in UI\ngit commit -m \"fix(ollyscale-ui): correct trace timeline rendering\"\n\n# Breaking change\ngit commit -m \"feat(api)!: redesign OTLP ingestion endpoint\n\nBREAKING CHANGE: The OTLP endpoint now requires authentication headers.\"\n\n# Chart update\ngit commit -m \"feat(chart-ollyscale): add support for external Redis\"\n</code></pre>"},{"location":"release-system/#release-tags","title":"Release Tags","text":"<p>Components are tagged with their component name prefix:</p> <ul> <li><code>ollyscale-v2.1.9</code> - ollyscale backend</li> <li><code>ollyscale-ui-v1.0.0</code> - ollyscale UI</li> <li><code>opamp-server-v1.0.1</code> - OpAMP server</li> <li><code>chart-ollyscale-v0.1.0</code> - ollyscale Helm chart</li> <li><code>demo-v0.1.0</code> - Demo application</li> <li><code>demo-otel-agent-v0.1.0</code> - Demo OTel agent</li> </ul>"},{"location":"release-system/#docker-image-tags","title":"Docker Image Tags","text":"<p>Each release creates multiple Docker image tags:</p> <pre><code>ghcr.io/ryanfaircloth/ollyscale/ollyscale:2.1.9      # Exact version\nghcr.io/ryanfaircloth/ollyscale/ollyscale:2.1        # Minor version\nghcr.io/ryanfaircloth/ollyscale/ollyscale:2          # Major version\nghcr.io/ryanfaircloth/ollyscale/ollyscale:latest     # Latest (production only)\n</code></pre>"},{"location":"release-system/#helm-chart-publishing","title":"Helm Chart Publishing","text":"<p>Charts are published to OCI registry:</p> <pre><code># Add the chart repository\nhelm repo add ollyscale oci://ghcr.io/ryanfaircloth/ollyscale/charts\n\n# Install a specific version\nhelm install ollyscale oci://ghcr.io/ryanfaircloth/ollyscale/charts/ollyscale --version 0.1.0\n\n# Install latest version\nhelm install ollyscale oci://ghcr.io/ryanfaircloth/ollyscale/charts/ollyscale\n</code></pre>"},{"location":"release-system/#troubleshooting","title":"Troubleshooting","text":""},{"location":"release-system/#release-pr-not-created","title":"Release PR not created","text":"<p>Check that:</p> <ol> <li>Commits follow Conventional Commit format</li> <li>Changes are in the component's directory</li> <li>Commits were pushed to <code>main</code> branch</li> </ol>"},{"location":"release-system/#chart-not-bumped-when-app-changes","title":"Chart not bumped when app changes","text":"<p>Verify in <code>release-please-config.json</code>:</p> <ol> <li>The app component updates the chart's <code>values.yaml</code> in its <code>extra-files</code></li> <li>The chart has corresponding entry with <code>bumpDependents: true</code></li> <li>The <code>component</code> name matches exactly</li> </ol>"},{"location":"release-system/#build-failures","title":"Build failures","text":"<p>Check GitHub Actions logs:</p> <ol> <li>Docker build step - may need to fix Dockerfile issues</li> <li>Helm package step - may need to fix Chart.yaml issues</li> <li>Registry push step - check credentials and permissions</li> </ol>"},{"location":"release-system/#development-workflow","title":"Development Workflow","text":""},{"location":"release-system/#testing-changes-locally","title":"Testing Changes Locally","text":"<pre><code># Build locally\ncd apps/ollyscale\ndocker build -t ollyscale:dev -f Dockerfile .\n\n# Test Helm chart\ncd charts/ollyscale\nhelm install ollyscale-dev . --values values-local-dev.yaml\n</code></pre>"},{"location":"release-system/#validating-release-configuration","title":"Validating Release Configuration","text":"<p>Run the validation checks locally:</p> <pre><code># Validate JSON files\njq empty release-please-config.json\njq empty .release-please-manifest.json\n\n# Check for duplicate components\njq -r '.packages[].component' release-please-config.json | sort | uniq -d\n\n# Verify extra-files exist\njq -r '.packages[] | .[\"extra-files\"][]? | if type == \"string\" then . else .path end' \\\n  release-please-config.json | while read -r file; do\n  [ -f \"$file\" ] &amp;&amp; echo \"\u2705 $file\" || echo \"\u274c $file\"\ndone\n</code></pre>"},{"location":"release-system/#migration-from-semantic-release","title":"Migration from semantic-release","text":"<p>The old semantic-release system has been replaced with release-please. Key differences:</p> <p>semantic-release (old):</p> <ul> <li>Single monolithic release for all components</li> <li>Required <code>@anolilab/multi-semantic-release</code> plugin</li> <li>Complex plugin configuration per component</li> <li>Released everything together</li> </ul> <p>release-please (new):</p> <ul> <li>Independent releases per component</li> <li>Native multi-package support</li> <li>Simpler configuration</li> <li><code>bumpDependents</code> handles cross-component dependencies</li> <li>Separate PRs for better visibility</li> </ul>"},{"location":"release-system/#references","title":"References","text":"<ul> <li>release-please documentation</li> <li>Conventional Commits</li> <li>Forked release-please with bumpDependents</li> <li>GitHub Container Registry</li> <li>Helm OCI Registry</li> </ul>"},{"location":"technical/","title":"Technical Details","text":""},{"location":"technical/#architecture","title":"Architecture","text":""},{"location":"technical/#data-storage","title":"Data Storage","text":"<ul> <li>Format: Full OpenTelemetry (OTEL) format for traces, logs, and metrics</li> <li>Redis: All telemetry stored with 30-minute TTL (compressed with ZSTD + msgpack)</li> <li>Sorted Sets: Time-series data indexed by timestamp</li> <li>Correlation: Native trace-metric-log correlation via trace/span IDs</li> <li>Cardinality Protection: Prevents metric explosion</li> <li>No Persistence: Data vanishes after TTL (ephemeral dev tool)</li> </ul>"},{"location":"technical/#otlp-compatibility","title":"OTLP Compatibility","text":"<p>ollyScale is fully OpenTelemetry-native:</p> <ul> <li>Ingestion: Accepts OTLP/gRPC (primary) and OTLP/HTTP</li> <li>Storage: Stores traces, logs, and metrics in full OTEL format with resources, scopes, and attributes</li> <li>Correlation: Native support for trace/span ID correlation across all telemetry types</li> <li>REST API: Exposes OTEL-formatted JSON for programmatic access</li> <li>Control Plane: OpenTelemetry Collector OpAmp for dynamic configuration</li> </ul>"},{"location":"demos/","title":"Demo Applications","text":"<p>ollyScale includes several demo applications to help you explore its observability capabilities. These demos range from simple microservices to complex distributed systems.</p>"},{"location":"demos/#available-demos","title":"Available Demos","text":""},{"location":"demos/#custom-demo-applications","title":"Custom Demo Applications","text":"<p>Simple Python Flask microservices demonstrating core observability features:</p> <ul> <li>Services: demo-frontend and demo-backend</li> <li>Languages: Python</li> <li>Features: Auto-traffic generation, distributed tracing, Prometheus metrics</li> <li>Resource Usage: Low (~256MB)</li> <li>Best For: Quick testing, development, learning basics</li> </ul> <p>Key Highlights:</p> <ul> <li>Automatic traffic generation every 3-8 seconds</li> <li>Multiple endpoints (simple requests, calculations, complex orders, errors)</li> <li>Easy to understand and modify</li> <li>Minimal resource requirements</li> </ul> <p>View Documentation \u2192</p>"},{"location":"demos/#opentelemetry-demo","title":"OpenTelemetry Demo","text":"<p>The official OpenTelemetry demo application (\"Astronomy Shop\"):</p> <ul> <li>Services: 11+ microservices</li> <li>Languages: Go, Java, Python, .NET, Node.js, Rust, Ruby, PHP</li> <li>Features: E-commerce workflows, built-in load generator, multi-language instrumentation</li> <li>Resource Usage: High (~2-4GB)</li> <li>Best For: Comprehensive demos, training, polyglot environments</li> </ul> <p>Key Highlights:</p> <ul> <li>Production-realistic distributed system</li> <li>Showcases OTel instrumentation across 7+ languages</li> <li>Complex distributed traces (10-20 spans)</li> <li>Realistic user workflows (browse, cart, checkout, payment)</li> </ul> <p>View Documentation \u2192</p>"},{"location":"demos/#advanced-demos","title":"Advanced Demos","text":""},{"location":"demos/#ebpf-zero-code-tracing","title":"eBPF Zero-Code Tracing","text":"<p>Automatic distributed tracing without code changes using eBPF:</p> <ul> <li>Technology: eBPF with Beyla auto-instrumentation</li> <li>Features: Zero-code instrumentation, HTTP/gRPC tracing</li> <li>Best For: Legacy applications, no-modification observability</li> </ul> <p>View Documentation \u2192</p>"},{"location":"demos/#ai-agent-with-ollama","title":"AI Agent with Ollama","text":"<p>GenAI observability demo with LLM instrumentation:</p> <ul> <li>Technology: Ollama LLM with OTel instrumentation</li> <li>Features: LLM span attributes, token tracking, prompt/response logging</li> <li>Best For: AI/ML observability, GenAI applications</li> </ul> <p>View Documentation \u2192</p>"},{"location":"demos/#quick-comparison","title":"Quick Comparison","text":"Demo Complexity Services Languages Resource Usage Auto-Traffic Custom Demo Simple 2 Python Low \u2705 OTel Demo Complex 11+ 7+ High \u2705 eBPF Demo Medium 2 Go Low \u274c AI Agent Simple 1 Python Medium \u2705"},{"location":"demos/#deployment","title":"Deployment","text":"<p>All demos can be deployed via:</p>"},{"location":"demos/#helm","title":"Helm","text":"<pre><code># Custom Demo\nhelm install ollyscale-demos charts/ollyscale-demos \\\n  --namespace ollyscale-demos \\\n  --create-namespace\n\n# OTel Demo\nhelm install ollyscale-demos charts/ollyscale-demos \\\n  --set customDemo.enabled=false \\\n  --set otelDemo.enabled=true\n</code></pre>"},{"location":"demos/#terraformargocd-recommended","title":"Terraform/ArgoCD (Recommended)","text":"<pre><code>cd .kind\n\n# Enable Custom Demo\nterraform apply -var=\"custom_demo_enabled=true\"\n\n# Enable OTel Demo\nterraform apply -var=\"otel_demo_enabled=true\" -var=\"custom_demo_enabled=false\"\n</code></pre>"},{"location":"demos/#accessing-demos","title":"Accessing Demos","text":"<p>After deployment, demos are available via HTTPRoutes:</p> <ul> <li>Custom Demo Frontend: <code>https://demo-frontend.ollyscale.test:49443</code></li> <li>OTel Demo: <code>https://otel-demo.ollyscale.test:49443</code></li> <li>ollyScale UI: <code>https://ollyscale.ollyscale.test:49443</code></li> </ul>"},{"location":"demos/#viewing-telemetry","title":"Viewing Telemetry","text":"<p>All demos send telemetry to ollyScale. Open the ollyScale UI to explore:</p> <ol> <li>Service Map: Visual representation of service dependencies</li> <li>Traces: Distributed traces with timing and attributes</li> <li>Logs: Application logs with trace correlation</li> <li>Metrics: RED metrics (Rate, Errors, Duration)</li> </ol>"},{"location":"demos/#choosing-a-demo","title":"Choosing a Demo","text":"<p>For Learning/Development:</p> <ul> <li>Start with Custom Demo - simple, fast, easy to understand</li> </ul> <p>For Demonstrations/Training:</p> <ul> <li>Use OTel Demo - comprehensive, production-realistic</li> </ul> <p>For Polyglot Environments:</p> <ul> <li>Use OTel Demo - showcases multiple languages</li> </ul> <p>For Legacy Applications:</p> <ul> <li>Try eBPF Demo - no code changes required</li> </ul> <p>For AI/ML Workloads:</p> <ul> <li>Try AI Agent - GenAI-specific instrumentation</li> </ul>"},{"location":"demos/#migration","title":"Migration","text":"<p>If you're migrating from the old <code>k8s-demo/</code> or <code>k8s-otel-demo/</code> directories, see the migration sections in:</p> <ul> <li>Custom Demo Migration</li> <li>OTel Demo Migration</li> </ul>"},{"location":"demos/#support","title":"Support","text":"<p>For issues or questions:</p> <ul> <li>GitHub Issues</li> <li>Documentation</li> </ul>"},{"location":"demos/custom-demo/","title":"Custom Demo Applications","text":"<p>The custom demo applications provide a simple but realistic microservice architecture for demonstrating ollyScale's observability capabilities.</p>"},{"location":"demos/custom-demo/#overview","title":"Overview","text":"<p>The demo consists of two Python Flask applications that automatically generate OpenTelemetry traces, logs, and Prometheus metrics:</p> <ul> <li>demo-frontend: User-facing service with multiple endpoints</li> <li>demo-backend: Backend service for data processing</li> </ul> <p>Both applications feature automatic traffic generation - they create distributed traces every 3-8 seconds without external input.</p>"},{"location":"demos/custom-demo/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  demo-frontend  \u2502  Port 5000 (HTTP)\n\u2502   (Flask)       \u2502  Port 8000 (Prometheus metrics)\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502 HTTP\n         \u2502 OTLP gRPC \u2192 gateway-collector:4317\n         \u2502 Prom \u2192 gateway-collector:19291\n         \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  demo-backend   \u2502  Port 5000 (HTTP)\n\u2502   (Flask)       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502 OTLP gRPC \u2192 gateway-collector:4317\n         \u2193\n    ollyScale UI\n</code></pre>"},{"location":"demos/custom-demo/#frontend-endpoints","title":"Frontend Endpoints","text":""},{"location":"demos/custom-demo/#-home","title":"<code>/</code> - Home","text":"<p>Returns service information and available endpoints.</p> <p>Example:</p> <pre><code>curl https://demo-frontend.ollyscale.test:49443/\n</code></pre>"},{"location":"demos/custom-demo/#hello-simple-request","title":"<code>/hello</code> - Simple Request","text":"<p>Basic endpoint that returns a greeting. Generates simple traces.</p> <p>Example:</p> <pre><code>curl https://demo-frontend.ollyscale.test:49443/hello\n</code></pre>"},{"location":"demos/custom-demo/#calculate-backend-interaction","title":"<code>/calculate</code> - Backend Interaction","text":"<p>Calls the backend to perform a calculation. Demonstrates service-to-service tracing.</p> <p>Example:</p> <pre><code>curl https://demo-frontend.ollyscale.test:49443/calculate\n</code></pre> <p>Response:</p> <pre><code>{\n  \"operation\": \"add\",\n  \"a\": 42,\n  \"b\": 17,\n  \"result\": 59\n}\n</code></pre>"},{"location":"demos/custom-demo/#error-error-scenario","title":"<code>/error</code> - Error Scenario","text":"<p>Intentionally triggers an exception to demonstrate error tracking.</p> <p>Example:</p> <pre><code>curl https://demo-frontend.ollyscale.test:49443/error\n</code></pre>"},{"location":"demos/custom-demo/#process-order-complex-distributed-trace","title":"<code>/process-order</code> - Complex Distributed Trace","text":"<p>Creates a multi-span distributed trace across frontend and backend:</p> <ol> <li>Frontend receives order request</li> <li>Backend validates order</li> <li>Backend processes payment</li> <li>Backend checks inventory</li> <li>Order completion</li> </ol> <p>Example:</p> <pre><code>curl https://demo-frontend.ollyscale.test:49443/process-order\n</code></pre> <p>Response:</p> <pre><code>{\n  \"status\": \"success\",\n  \"order_id\": 7342,\n  \"details\": {\n    \"status\": \"success\",\n    \"order_id\": 7342,\n    \"processing_time_ms\": 287\n  }\n}\n</code></pre>"},{"location":"demos/custom-demo/#backend-endpoints","title":"Backend Endpoints","text":""},{"location":"demos/custom-demo/#health-health-check","title":"<code>/health</code> - Health Check","text":"<p>Kubernetes liveness/readiness probe endpoint.</p>"},{"location":"demos/custom-demo/#calculate-math-operations","title":"<code>/calculate</code> - Math Operations","text":"<p>Performs simple calculations with span attributes showing operands and results.</p>"},{"location":"demos/custom-demo/#process-order-processing","title":"<code>/process</code> - Order Processing","text":"<p>Handles order processing with multiple sub-operations (validation, payment, inventory).</p>"},{"location":"demos/custom-demo/#observability-features","title":"Observability Features","text":""},{"location":"demos/custom-demo/#opentelemetry-traces","title":"OpenTelemetry Traces","text":"<p>Both services are instrumented with OpenTelemetry auto-instrumentation:</p> <ul> <li>Flask instrumentation: Automatic HTTP server spans</li> <li>Requests instrumentation: Automatic HTTP client spans</li> <li>Custom spans: Business logic operations with attributes</li> </ul> <p>Span attributes include:</p> <ul> <li><code>http.method</code>, <code>http.route</code>, <code>http.status_code</code></li> <li><code>calculation.operand_a</code>, <code>calculation.operand_b</code>, <code>calculation.result</code></li> <li><code>order.id</code>, <code>order.status</code></li> <li><code>payment.amount</code>, <code>payment.method</code></li> </ul>"},{"location":"demos/custom-demo/#prometheus-metrics","title":"Prometheus Metrics","text":"<p>Frontend exports custom metrics:</p> <ul> <li><code>demo_frontend_requests_total{endpoint, status}</code>: Request counter</li> <li><code>demo_frontend_request_duration_seconds{endpoint}</code>: Request histogram</li> </ul> <p>Metrics are scraped from port 8000 and pushed to the OTel Collector via remote write.</p>"},{"location":"demos/custom-demo/#automatic-traffic-generation","title":"Automatic Traffic Generation","text":"<p>The frontend includes a background thread that continuously generates requests:</p> <ul> <li>50%: Process orders (complex traces)</li> <li>20%: Calculate (service-to-service)</li> <li>20%: Hello (simple requests)</li> <li>10%: Errors (failure scenarios)</li> </ul> <p>Requests occur every 3-8 seconds with random intervals.</p>"},{"location":"demos/custom-demo/#deployment","title":"Deployment","text":""},{"location":"demos/custom-demo/#helm-installation","title":"Helm Installation","text":"<pre><code># Install demos chart\nhelm install ollyscale-demos charts/ollyscale-demos \\\n  --namespace ollyscale-demos \\\n  --create-namespace \\\n  --values charts/ollyscale-demos/values-local-dev.yaml\n</code></pre>"},{"location":"demos/custom-demo/#argocd-deployment-recommended","title":"ArgoCD Deployment (Recommended)","text":"<p>The demos are managed by ArgoCD via Terraform:</p> <pre><code># Enable custom demo in Terraform\ncd .kind\nterraform apply -var=\"custom_demo_enabled=true\"\n</code></pre>"},{"location":"demos/custom-demo/#configuration-options","title":"Configuration Options","text":"<p>Enable/disable via Helm values:</p> <pre><code>customDemo:\n  enabled: true # Set to false to disable\n\n  frontend:\n    image:\n      repository: ghcr.io/ryanfaircloth/demo-frontend\n      tag: latest\n\n    env:\n      otelExporterOtlpEndpoint: \"http://gateway-collector.ollyscale.svc.cluster.local:4317\"\n      otelServiceName: \"demo-frontend\"\n\n  backend:\n    image:\n      repository: ghcr.io/ryanfaircloth/demo-backend\n      tag: latest\n</code></pre>"},{"location":"demos/custom-demo/#access","title":"Access","text":"<p>After deployment, access the frontend via HTTPRoute:</p> <pre><code># Check deployment status\nkubectl get pods -n ollyscale-demos\n\n# Access frontend\ncurl https://demo-frontend.ollyscale.test:49443/\n\n# Or use port-forward\nkubectl port-forward -n ollyscale-demos svc/demo-frontend 5000:5000\ncurl http://localhost:5000/\n</code></pre>"},{"location":"demos/custom-demo/#viewing-telemetry","title":"Viewing Telemetry","text":"<p>Open ollyScale UI at <code>https://ollyscale.ollyscale.test</code> to see:</p> <ol> <li>Service Map: Visual graph showing frontend \u2192 backend relationships</li> <li>Traces: Distributed traces with detailed timing and attributes</li> <li>Logs: Application logs with trace context</li> <li>Metrics: RED metrics (Rate, Errors, Duration) per service</li> </ol>"},{"location":"demos/custom-demo/#development","title":"Development","text":""},{"location":"demos/custom-demo/#building-local-images","title":"Building Local Images","text":"<pre><code># Build and push to local registry\ncd charts\n./build-and-push-local.sh v2.1.x-custom-demo\n\n# Images will be built and pushed:\n# - registry.ollyscale.test:49443/ollyscale/demo-frontend:v2.1.x-custom-demo\n# - registry.ollyscale.test:49443/ollyscale/demo-backend:v2.1.x-custom-demo\n</code></pre>"},{"location":"demos/custom-demo/#source-code","title":"Source Code","text":"<p>Demo source code is located in:</p> <ul> <li><code>apps/demo/frontend.py</code> - Frontend Flask application</li> <li><code>apps/demo/backend.py</code> - Backend Flask application</li> <li><code>apps/demo/requirements.txt</code> - Python dependencies</li> </ul> <p>Dockerfiles:</p> <ul> <li><code>docker/dockerfiles/Dockerfile.demo-frontend</code></li> <li><code>docker/dockerfiles/Dockerfile.demo-backend</code></li> </ul>"},{"location":"demos/custom-demo/#troubleshooting","title":"Troubleshooting","text":""},{"location":"demos/custom-demo/#pods-not-starting","title":"Pods not starting","text":"<pre><code># Check pod status\nkubectl describe pod -n ollyscale-demos -l app.kubernetes.io/name=demo-frontend\n\n# Check logs\nkubectl logs -n ollyscale-demos -l app.kubernetes.io/name=demo-frontend\n</code></pre>"},{"location":"demos/custom-demo/#no-telemetry-in-ollyscale","title":"No telemetry in ollyScale","text":"<ol> <li>Verify OTel Collector is running:</li> </ol> <pre><code>kubectl get pods -n ollyscale -l app.kubernetes.io/name=opentelemetry-collector\n</code></pre> <ol> <li>Check demo environment variables:</li> </ol> <pre><code>kubectl get deployment demo-frontend -n ollyscale-demos -o yaml | grep OTEL_\n</code></pre> <ol> <li>Test collector connectivity:</li> </ol> <pre><code>kubectl exec -n ollyscale-demos deployment/demo-frontend -- \\\n  curl -v gateway-collector.ollyscale.svc.cluster.local:4317\n</code></pre>"},{"location":"demos/custom-demo/#httproute-not-working","title":"HTTPRoute not working","text":"<pre><code># Check HTTPRoute status\nkubectl get httproute -n ollyscale-demos demo-frontend -o yaml\n\n# Verify Gateway\nkubectl get gateway -n envoy-gateway-system cluster-gateway\n</code></pre>"},{"location":"demos/custom-demo/#traffic-generation","title":"Traffic Generation","text":"<p>A traffic generation script is provided to continuously send requests to the custom demo and create realistic observability data.</p>"},{"location":"demos/custom-demo/#usage","title":"Usage","text":"<pre><code># From the charts/ollyscale-demos directory\ncd charts/ollyscale-demos\n./generate-custom-demo-traffic.sh\n</code></pre> <p>The script:</p> <ul> <li>Sends requests to <code>https://demo-frontend.ollyscale.test:49443</code> (no port-forward needed)</li> <li>Generates realistic traffic patterns:</li> <li>50%: <code>/process-order</code> - Complex distributed traces</li> <li>20%: <code>/calculate</code> - Service-to-service calls</li> <li>20%: <code>/hello</code> - Simple requests</li> <li>10%: <code>/error</code> - Error scenarios</li> <li>Displays real-time request status with color-coded output</li> <li>Uses random delays (0.5-2 seconds) between requests</li> </ul>"},{"location":"demos/custom-demo/#requirements","title":"Requirements","text":"<ul> <li>Custom demo deployed via Helm/ArgoCD</li> <li>HTTPRoute configured and working</li> <li>Envoy Gateway running</li> </ul> <p>Press <code>Ctrl+C</code> to stop the traffic generator.</p>"},{"location":"demos/custom-demo/#example-use-cases","title":"Example Use Cases","text":""},{"location":"demos/custom-demo/#testing-service-dependencies","title":"Testing Service Dependencies","text":"<p>Use the <code>/process-order</code> endpoint to generate complex traces showing multiple service interactions.</p>"},{"location":"demos/custom-demo/#error-tracking","title":"Error Tracking","text":"<p>The <code>/error</code> endpoint creates error traces with exception details for testing error monitoring.</p>"},{"location":"demos/custom-demo/#load-testing","title":"Load Testing","text":"<p>Run the traffic generation script or adjust its timing for sustained load testing.</p>"},{"location":"demos/custom-demo/#metrics-analysis","title":"Metrics Analysis","text":"<p>Export Prometheus metrics to analyze request rates, error rates, and latency distributions.</p>"},{"location":"demos/custom-demo/#migration-from-k8s-demo","title":"Migration from k8s-demo","text":"<p>If you previously used <code>k8s-demo/</code>, the new Helm chart provides:</p> <ul> <li>\u2705 Same functionality with cleaner deployment</li> <li>\u2705 HTTPRoute integration (no LoadBalancer needed)</li> <li>\u2705 GitOps-ready via ArgoCD</li> <li>\u2705 Easy enable/disable via values</li> <li>\u2705 Local registry support for development</li> </ul> <p>See Migration Guide for details.</p>"},{"location":"demos/otel-demo/","title":"OpenTelemetry Demo","text":"<p>The OpenTelemetry Demo is the official demo application from the OpenTelemetry project, showcasing a realistic microservices-based e-commerce system.</p>"},{"location":"demos/otel-demo/#overview","title":"Overview","text":"<p>The OTel Demo (also known as \"Astronomy Shop\") is a complete distributed system featuring:</p> <ul> <li>11+ microservices in multiple languages (Go, Java, Node.js, Python, .NET, Rust, PHP)</li> <li>Realistic workflows: Product browsing, shopping cart, checkout, payments</li> <li>Built-in load generator: Automatic traffic simulation</li> <li>Rich telemetry: Traces, metrics, logs across all services</li> </ul> <p>When deployed with ollyScale, all telemetry data is sent to ollyScale's collectors instead of bundled backends.</p>"},{"location":"demos/otel-demo/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  frontend       \u2502\u2500\u2500\u2500\u2500\u2192\u2502 productcatalog  \u2502     \u2502  currencyservice\u2502\n\u2502  (TypeScript)   \u2502     \u2502  (Go)           \u2502     \u2502  (.NET)         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u2502              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192\u2502 cartservice     \u2502\u2500\u2500\u2500\u2500\u2192\u2502 redis           \u2502\n         \u2502              \u2502  (Go)           \u2502     \u2502  (cache)        \u2502\n         \u2502              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u2502              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192\u2502 checkoutservice \u2502\u2500\u2500\u2500\u2500\u2192\u2502 paymentservice  \u2502\n                        \u2502  (Go)           \u2502     \u2502  (Node.js)      \u2502\n                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                 \u2502\n                                 \u2502              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192\u2502 shippingservice \u2502\n                                 \u2502              \u2502  (Rust)         \u2502\n                                 \u2502              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                 \u2502\n                                 \u2502              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192\u2502 emailservice    \u2502\n                                                \u2502  (Ruby)         \u2502\n                                                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                 \u2502\n                 \u2193 OTLP\n        gateway-collector \u2192 ollyScale UI\n</code></pre>"},{"location":"demos/otel-demo/#services","title":"Services","text":"Service Language Purpose frontend TypeScript Web UI and BFF (Backend for Frontend) productcatalog Go Product inventory and search cartservice Go Shopping cart management with Redis checkoutservice Go Order processing orchestration paymentservice Node.js Payment processing currencyservice .NET Currency conversion shippingservice Rust Shipping cost calculation emailservice Ruby Order confirmation emails recommendationservice Python Product recommendations adservice Java Advertisement serving loadgenerator Python/Locust Traffic simulation"},{"location":"demos/otel-demo/#features","title":"Features","text":""},{"location":"demos/otel-demo/#multi-language-instrumentation","title":"Multi-Language Instrumentation","text":"<p>The demo showcases OpenTelemetry instrumentation across:</p> <ul> <li>Go: Auto-instrumentation with <code>otelhttp</code>, <code>otelgrpc</code></li> <li>Java: Auto-instrumentation via agent</li> <li>Python: Auto-instrumentation via <code>opentelemetry-instrument</code></li> <li>.NET: Native OTel SDK</li> <li>Node.js: Auto-instrumentation via SDK</li> <li>Rust: Manual instrumentation</li> <li>Ruby: SDK instrumentation</li> </ul>"},{"location":"demos/otel-demo/#realistic-scenarios","title":"Realistic Scenarios","text":"<p>The load generator creates realistic user flows:</p> <ul> <li>Browse products</li> <li>Add items to cart</li> <li>View cart</li> <li>Checkout process</li> <li>Payment processing</li> <li>Shipping calculation</li> </ul>"},{"location":"demos/otel-demo/#rich-telemetry","title":"Rich Telemetry","text":"<p>Traces:</p> <ul> <li>Multi-service distributed traces</li> <li>gRPC and HTTP spans</li> <li>Database queries (Redis)</li> <li>External service calls</li> </ul> <p>Metrics:</p> <ul> <li>Request rates per service</li> <li>Error rates</li> <li>Latency histograms</li> <li>Custom business metrics</li> </ul> <p>Logs:</p> <ul> <li>Structured logs with trace context</li> <li>Error logs</li> <li>Business event logs</li> </ul>"},{"location":"demos/otel-demo/#deployment","title":"Deployment","text":""},{"location":"demos/otel-demo/#helm-installation","title":"Helm Installation","text":"<pre><code># Install OTel Demo via ollyscale-demos chart\nhelm install ollyscale-demos charts/ollyscale-demos \\\n  --namespace ollyscale-demos \\\n  --create-namespace \\\n  --set customDemo.enabled=false \\\n  --set otelDemo.enabled=true\n</code></pre>"},{"location":"demos/otel-demo/#argocd-deployment-recommended","title":"ArgoCD Deployment (Recommended)","text":"<p>Enable via Terraform:</p> <pre><code>cd .kind\nterraform apply -var=\"otel_demo_enabled=true\" -var=\"custom_demo_enabled=false\"\n</code></pre>"},{"location":"demos/otel-demo/#configuration","title":"Configuration","text":"<p>The demo is deployed as a subchart dependency with ollyScale configuration:</p> <pre><code>otelDemo:\n  enabled: true\n\n  httpRoute:\n    enabled: true\n    hostname: otel-demo.ollyscale.test\n\nopentelemetry-demo:\n  # Disable bundled observability backends\n  opentelemetry-collector:\n    enabled: false\n  jaeger:\n    enabled: false\n  grafana:\n    enabled: false\n  prometheus:\n    enabled: false\n  opensearch:\n    enabled: false\n\n  # Configure OTLP export to ollyScale\n  default:\n    env:\n      - name: OTEL_EXPORTER_OTLP_ENDPOINT\n        value: \"http://gateway-collector.ollyscale.svc.cluster.local:4318\"\n      - name: OTEL_EXPORTER_OTLP_PROTOCOL\n        value: \"http/protobuf\"\n</code></pre>"},{"location":"demos/otel-demo/#access","title":"Access","text":""},{"location":"demos/otel-demo/#web-ui","title":"Web UI","text":"<p>After deployment, access the frontend:</p> <pre><code># Via HTTPRoute\ncurl https://otel-demo.ollyscale.test/\n\n# Or browser\nopen https://otel-demo.ollyscale.test/\n</code></pre>"},{"location":"demos/otel-demo/#service-endpoints","title":"Service Endpoints","text":"<p>The frontend provides:</p> <ul> <li>Homepage: Product catalog</li> <li>Product details: Individual product pages</li> <li>Cart: Shopping cart management</li> <li>Checkout: Order placement</li> </ul>"},{"location":"demos/otel-demo/#viewing-telemetry","title":"Viewing Telemetry","text":"<p>Open ollyScale UI at <code>https://ollyscale.ollyscale.test</code> to explore:</p>"},{"location":"demos/otel-demo/#service-map","title":"Service Map","text":"<p>See all 11+ services and their relationships:</p> <ul> <li>Frontend calling multiple backend services</li> <li>Checkout orchestrating payment, shipping, email</li> <li>Product catalog serving frontend and recommendations</li> </ul>"},{"location":"demos/otel-demo/#distributed-traces","title":"Distributed Traces","text":"<p>Example trace flow for checkout:</p> <ol> <li><code>frontend</code> - User initiates checkout</li> <li><code>checkoutservice</code> - Orchestrates order processing</li> <li><code>cartservice</code> - Retrieves cart items from Redis</li> <li><code>productcatalog</code> - Gets product details</li> <li><code>currencyservice</code> - Converts prices</li> <li><code>paymentservice</code> - Processes payment</li> <li><code>shippingservice</code> - Calculates shipping</li> <li><code>emailservice</code> - Sends confirmation</li> </ol> <p>Traces show:</p> <ul> <li>Total duration: ~500ms-2s</li> <li>Service-level timings</li> <li>gRPC/HTTP method details</li> <li>Error conditions</li> </ul>"},{"location":"demos/otel-demo/#metrics","title":"Metrics","text":"<p>View RED metrics per service:</p> <ul> <li>Rate: Requests/second</li> <li>Errors: Error rate %</li> <li>Duration: p50, p95, p99 latencies</li> </ul>"},{"location":"demos/otel-demo/#logs","title":"Logs","text":"<p>Application logs with:</p> <ul> <li>Trace IDs for correlation</li> <li>Structured fields (service, level, message)</li> <li>Error stack traces</li> </ul>"},{"location":"demos/otel-demo/#resource-requirements","title":"Resource Requirements","text":"<p>The OTel Demo is more resource-intensive than the custom demo:</p> <pre><code># Recommended resources for local dev\nresources:\n  requests:\n    memory: \"2Gi\"\n    cpu: \"1000m\"\n  limits:\n    memory: \"4Gi\"\n    cpu: \"2000m\"\n</code></pre> <p>Note: For local KIND clusters, ensure Docker/Podman has sufficient resources allocated (at least 4GB RAM).</p>"},{"location":"demos/otel-demo/#load-generation","title":"Load Generation","text":"<p>The demo includes an automatic load generator that:</p> <ul> <li>Simulates realistic user behavior</li> <li>Generates continuous traffic</li> <li>Creates diverse trace patterns</li> <li>Includes error scenarios</li> </ul> <p>To adjust load intensity, modify the load generator settings in Helm values.</p>"},{"location":"demos/otel-demo/#use-cases","title":"Use Cases","text":""},{"location":"demos/otel-demo/#multi-language-observability","title":"Multi-Language Observability","text":"<p>Perfect for testing ollyScale with polyglot microservices. See how different languages export telemetry.</p>"},{"location":"demos/otel-demo/#complex-distributed-traces","title":"Complex Distributed Traces","text":"<p>Explore deeply nested traces with 5-10 spans across multiple services.</p>"},{"location":"demos/otel-demo/#service-mesh-testing","title":"Service Mesh Testing","text":"<p>If using Istio or Linkerd, see how mesh-generated spans integrate with application spans.</p>"},{"location":"demos/otel-demo/#performance-analysis","title":"Performance Analysis","text":"<p>Identify bottlenecks in the checkout flow by analyzing trace timings.</p>"},{"location":"demos/otel-demo/#troubleshooting","title":"Troubleshooting","text":""},{"location":"demos/otel-demo/#high-resource-usage","title":"High Resource Usage","text":"<pre><code># Check pod resource usage\nkubectl top pods -n ollyscale-demos\n\n# Scale down load generator\nkubectl scale deployment loadgenerator -n ollyscale-demos --replicas=0\n</code></pre>"},{"location":"demos/otel-demo/#services-not-starting","title":"Services Not Starting","text":"<pre><code># Check pod status\nkubectl get pods -n ollyscale-demos\n\n# Describe failing pod\nkubectl describe pod &lt;pod-name&gt; -n ollyscale-demos\n\n# Check logs\nkubectl logs &lt;pod-name&gt; -n ollyscale-demos\n</code></pre>"},{"location":"demos/otel-demo/#no-telemetry","title":"No Telemetry","text":"<p>Verify OTLP endpoint configuration:</p> <pre><code># Check environment variable\nkubectl get deployment frontend -n ollyscale-demos -o yaml | grep OTEL_EXPORTER\n\n# Test collector connectivity\nkubectl exec -n ollyscale-demos deployment/frontend -- \\\n  curl -v gateway-collector.ollyscale.svc.cluster.local:4318\n</code></pre>"},{"location":"demos/otel-demo/#httproute-not-working","title":"HTTPRoute Not Working","text":"<pre><code># Check HTTPRoute\nkubectl get httproute otel-demo-frontend -n ollyscale-demos -o yaml\n\n# Verify backend service\nkubectl get svc -n ollyscale-demos | grep frontendproxy\n</code></pre>"},{"location":"demos/otel-demo/#chart-version","title":"Chart Version","text":"<p>The ollyscale-demos chart uses OpenTelemetry Demo Helm chart version:</p> <pre><code>dependencies:\n  - name: opentelemetry-demo\n    version: \"0.33.0\"\n    repository: https://open-telemetry.github.io/opentelemetry-helm-charts\n</code></pre> <p>To update to a newer version, modify <code>charts/ollyscale-demos/Chart.yaml</code> and run:</p> <pre><code>cd charts/ollyscale-demos\nhelm dependency update\n</code></pre>"},{"location":"demos/otel-demo/#comparison-with-custom-demo","title":"Comparison with Custom Demo","text":"Feature Custom Demo OTel Demo Services 2 11+ Languages Python Go, Java, Python, .NET, Node.js, Rust, Ruby Complexity Simple Production-realistic Resource Usage Low (~256MB) High (~2-4GB) Traces 3-5 spans 10-20 spans Best For Quick testing, development Comprehensive demos, training"},{"location":"demos/otel-demo/#migration-from-k8s-otel-demo","title":"Migration from k8s-otel-demo","text":"<p>If you previously used <code>k8s-otel-demo/</code>, the new Helm chart provides:</p> <ul> <li>\u2705 Same demo application, cleaner deployment</li> <li>\u2705 HTTPRoute integration for ingress</li> <li>\u2705 GitOps-ready via ArgoCD</li> <li>\u2705 Managed as subchart dependency</li> <li>\u2705 Automatic OTLP configuration</li> </ul> <p>See Migration Guide for details.</p>"},{"location":"demos/otel-demo/#references","title":"References","text":"<ul> <li>OpenTelemetry Demo Documentation</li> <li>Demo GitHub Repository</li> <li>Demo Helm Chart</li> </ul>"}]}