# PostgreSQL Infrastructure for ollyScale v2

This document describes the PostgreSQL infrastructure setup for ollyScale v2.

## Architecture

### Components

1. **Zalando Postgres Operator** - Deploys and manages PostgreSQL clusters
   - Location: `.kind/modules/main/argocd-applications/middleware/postgres-operator.yaml`
   - Namespace: `postgres-operator`
   - Sync Wave: 30 (after Strimzi at wave 20, before Redis at wave 35)
   - Chart: `https://opensource.zalando.com/postgres-operator/charts/postgres-operator`
   - Version: 1.14.0

2. **PostgreSQL Database Cluster** - HA database for ollyScale
   - Location: `charts/ollyscale/templates/postgresql.yaml`
   - Namespace: `ollyscale`
   - Managed by: Zalando Postgres Operator
   - Features:
     - 2 replicas with streaming replication
     - Synchronous replication (patroni)
     - Connection pooler (PgBouncer) for efficient connection management
     - Automatic failover via Patroni

### Deployment Order

1. **postgres-operator** (sync-wave: 30) - Installs CRDs and operator
2. **ollyscale chart** - Deploys Postgresql CR, creates database cluster

## Configuration

### Operator Configuration

```yaml
# .kind/modules/main/argocd-applications/middleware/postgres-operator.yaml
configKubernetes:
  enable_pod_antiaffinity: true          # Spread replicas across nodes
  enable_pod_disruption_budget: true     # Protect from disruptions
  watched_namespace: "*"                  # Watch all namespaces
```

### Database Configuration

```yaml
# charts/ollyscale/values.yaml
postgresql:
  teamId: ollyscale
  numberOfInstances: 2                    # Primary + 1 replica
  volume:
    size: 10Gi
    storageClass: ''                      # Use default StorageClass
  databases:
    ollyscale: ollyscale                  # database: owner
  users:
    ollyscale:
      - superuser
      - createdb
  postgresql:
    version: '18'
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 1000m
      memory: 1Gi
  patroni:
    synchronous_mode: true                # Sync replication for durability
    synchronous_mode_strict: false        # Allow async if replica unavailable
```

## Connection Details

### From Frontend Application

Both the frontend API and OTLP receiver automatically receive these environment variables:

```bash
DATABASE_HOST=ollyscale-db-pooler        # PgBouncer connection pooler
DATABASE_PORT=5432
DATABASE_NAME=ollyscale
DATABASE_USER=<from secret>              # Auto-generated by operator
DATABASE_PASSWORD=<from secret>          # Auto-generated by operator
```

### Secret Name Pattern

The operator creates a secret with credentials:

```text
ollyscale.<chart-name>-db.credentials.postgresql.acid.zalan.do
```

Keys:

- `username` - Database username (ollyscale)
- `password` - Auto-generated password

### Connection String

```python
# SQLAlchemy connection string
DATABASE_URL = (
    f"postgresql+asyncpg://{DATABASE_USER}:{DATABASE_PASSWORD}@"
    f"{DATABASE_HOST}:{DATABASE_PORT}/{DATABASE_NAME}"
)
```

## Services Created

1. **ollyscale-db** - Direct PostgreSQL service (for admin)
   - Port: 5432
   - Endpoints: Primary and replica pods

2. **ollyscale-db-pooler** - PgBouncer connection pooler (for apps)
   - Port: 5432
   - Mode: transaction
   - Replicas: 2

3. **ollyscale-db-replica** - Read-only replica service
   - Port: 5432
   - Endpoints: Replica pods only

## Deployment

### Deploy Operator

```bash
cd .kind
terraform apply -target='kubectl_manifest.middleware_applications["middleware/postgres-operator.yaml"]'
```

### Deploy Database

```bash
cd charts
helm upgrade --install ollyscale ./ollyscale \
  --namespace ollyscale \
  --create-namespace
```

**Migration Strategy**: Database schema migrations run automatically as a Kubernetes Job:

- Helm hook: `pre-upgrade,pre-install` (runs before deployment updates)
- Hook weight: `-5` (runs early in the upgrade sequence)
- Uses same image as frontend but executes `alembic upgrade head`
- Runs exactly once per deployment (no race conditions between replicas)
- Failed migrations block the rollout (safety mechanism)
- Auto-cleanup after 5 minutes on success

### Verify Deployment

```bash
# Check operator
kubectl get pods -n postgres-operator

# Check migration job (only exists during upgrade)
kubectl get jobs -n ollyscale | grep migration

# Check database cluster
kubectl get postgresql -n ollyscale
kubectl get pods -n ollyscale -l application=spilo

# Check services
kubectl get svc -n ollyscale | grep db

# Get credentials
kubectl get secret -n ollyscale \
  ollyscale.ollyscale-db.credentials.postgresql.acid.zalan.do \
  -o jsonpath='{.data.username}' | base64 -d
kubectl get secret -n ollyscale \
  ollyscale.ollyscale-db.credentials.postgresql.acid.zalan.do \
  -o jsonpath='{.data.password}' | base64 -d
```

## Testing Connection

```bash
# Port-forward to pooler
kubectl port-forward -n ollyscale svc/ollyscale-db-pooler 5432:5432

# Connect with psql
psql -h localhost -U ollyscale -d ollyscale
```

## High Availability

### Automatic Failover

Patroni manages automatic failover:

1. Health checks detect primary failure
2. Replica promoted to primary (< 30 seconds)
3. Services updated to point to new primary
4. Failed pod restarted as replica

### Synchronous Replication

- `synchronous_mode: true` - Writes wait for replica ACK
- `synchronous_mode_strict: false` - Allow async if replica down (availability over consistency)

### Connection Pooling

PgBouncer provides:

- Connection reuse (reduces overhead)
- Transaction-level pooling
- 2 pooler instances for HA
- Automatic load balancing

## Monitoring

### Check Cluster Status

```bash
# Patroni cluster info
kubectl exec -n ollyscale ollyscale-db-0 -- \
  patronictl list

# Replication status
kubectl exec -n ollyscale ollyscale-db-0 -- \
  psql -U postgres -c "SELECT * FROM pg_stat_replication;"
```

### Common Issues

**Issue**: Pods stuck in Pending

- Check: `kubectl get events -n ollyscale`
- Likely: Insufficient resources or missing StorageClass

**Issue**: Database not created

- Check operator logs: `kubectl logs -n postgres-operator deployment/postgres-operator`
- Check postgresql status: `kubectl describe postgresql -n ollyscale ollyscale-db`

**Issue**: Can't connect from frontend

- Verify secret exists: `kubectl get secret -n ollyscale | grep credentials`
- Check pooler service: `kubectl get svc -n ollyscale ollyscale-db-pooler`
- Check frontend logs: `kubectl logs -n ollyscale deployment/ollyscale-frontend`

## Resource Management

### Disk Usage

```bash
# Check PVC usage
kubectl exec -n ollyscale ollyscale-db-0 -- df -h /home/postgres/pgdata
```

### Scaling

```bash
# Scale to 3 replicas
helm upgrade ollyscale ./ollyscale \
  --namespace ollyscale \
  --set postgresql.numberOfInstances=3 \
  --reuse-values
```

## Backup and Restore

### Manual Backup

```bash
# Backup via pg_dump
kubectl exec -n ollyscale ollyscale-db-0 -- \
  pg_dump -U ollyscale ollyscale > backup.sql
```

### Automated Backups (Future)

The operator supports WAL-E/WAL-G for continuous archiving:

```yaml
postgresql:
  backup:
    enabled: true
    s3_bucket: ollyscale-backups
    schedule: "0 2 * * *"
```

## Security

### Network Policies (Recommended)

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: ollyscale-db-policy
spec:
  podSelector:
    matchLabels:
      application: spilo
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app.kubernetes.io/component: frontend
    ports:
    - protocol: TCP
      port: 5432
```

### TLS Encryption (Future)

```yaml
postgresql:
  tls:
    secretName: ollyscale-db-tls
    caSecret: ollyscale-ca
```

## References

- [Zalando Postgres Operator Documentation](https://postgres-operator.readthedocs.io/)
- [Patroni Documentation](https://patroni.readthedocs.io/)
- [PgBouncer Documentation](https://www.pgbouncer.org/)
- [PostgreSQL High Availability](https://www.postgresql.org/docs/current/high-availability.html)
